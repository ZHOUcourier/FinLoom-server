#!/usr/bin/env python3
"""High level orchestration for the intelligent strategy workflow.

This module organises the end-to-end investment strategy pipeline and wraps the
existing functional modules (data, features, AI models, risk, execution and
backtesting) behind service classes. Each stage returns strongly typed
containers so downstream consumers (CLI, web API, UI) receive structured data
alongside human readable explanations when available.
"""

from __future__ import annotations

from dataclasses import dataclass, field
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional

import numpy as np
import pandas as pd

from ai_strategy_system.core.strategy_code_generator import (
    StrategyCode,
    StrategyCodeGenerator,
)
from common.data_structures import Signal
from common.logging_system import setup_logger
from module_00_environment.config_loader import ConfigLoader
from module_01_data_pipeline import (
    AkshareDataCollector,
    ChineseAlternativeDataCollector,
    ChineseFundamentalCollector,
)
from module_02_feature_engineering import TechnicalIndicators
from module_03_ai_models import (
    EnsembleConfig,
    EnsemblePredictor,
    LSTMModel,
    LSTMModelConfig,
    OnlineLearner,
    OnlineLearningConfig,
    PPOAgent,
    PPOConfig,
)
from module_04_market_analysis.regime_detection.market_regime_detector import (
    MarketRegimeDetector,
    RegimeDetectionConfig,
)
from module_05_risk_management import (
    MeanVarianceOptimizer,
    MVOConfig,
    OptimizationObjective,
)
from module_08_execution import (
    ExecutionDestination,
    FilterConfig,
    OrderManager,
    SignalFilter,
)
from module_09_backtesting import (
    BacktestConfig,
    BacktestEngine,
    BacktestReportGenerator,
    PerformanceAnalyzer,
    ReportConfig,
)
from module_10_ai_interaction import (
    HybridAIService,
    ParameterMapper,
    PortfolioRecommendation,
    RecommendationEngine,
    RequirementParser,
)

LOGGER_NAME = "strategy_workflow"
LOGGER = setup_logger(LOGGER_NAME)


@dataclass
class RequirementContext:
    """Structured output of the user requirement understanding stage."""

    raw_text: str
    parsed_requirement: Any
    system_params: Dict[str, Any]
    portfolio_recommendations: List[PortfolioRecommendation]
    explanation: Optional[str] = None


@dataclass
class MarketContext:
    """Snapshot of current market regime, sentiment and macro signals."""

    as_of: datetime
    regime: Dict[str, Any]
    sentiment: Dict[str, Any]
    macro_summary: Dict[str, Any]
    data_sources: Dict[str, str] = field(default_factory=dict)


@dataclass
class UniverseSelection:
    """Represents the investable universe selected for the strategy."""

    symbols: List[str]
    rationale: str
    selection_notes: Dict[str, Any] = field(default_factory=dict)


@dataclass
class FeatureBundle:
    """Container for engineered features and supporting metadata."""

    combined_features: pd.DataFrame
    train_data: pd.DataFrame
    returns_by_symbol: Dict[str, pd.Series]
    raw_market_data: Dict[str, pd.DataFrame]
    prepared_at: datetime


@dataclass
class ModelChoice:
    """Description of the selected modelling approach."""

    model_type: str
    config: Dict[str, Any]
    reason: str


@dataclass
class ModelSelectionResult:
    """Result of model training including trained instance and diagnostics."""

    choice: ModelChoice
    model: Any
    training_metadata: Dict[str, Any]


@dataclass
class StrategyParameters:
    """Parameters governing the trading strategy derived from the workflow."""

    buy_threshold: float
    confidence_threshold: float
    max_position: float
    style: str


@dataclass
class PortfolioPlan:
    """Portfolio allocation and risk summary ready for execution."""

    weights: Dict[str, float]
    cash_buffer: float
    risk_metrics: Dict[str, Any]


@dataclass
class ExecutionPlan:
    """High level execution blueprint built from the portfolio plan."""

    orders: List[Dict[str, Any]]
    algorithm: str
    notes: Optional[str] = None


@dataclass
class BacktestSummary:
    """Aggregated performance metrics and report artefacts."""

    result: Any
    performance_report: Any
    report_files: Dict[str, str]
    backtest_id: Optional[str] = None
    strategy_code: Optional[Any] = None  # StrategyCode instance
    strategy_id: Optional[str] = None  # ç­–ç•¥æŒä¹…åŒ–ID


@dataclass
class StrategyWorkflowResult:
    """Final consolidated result returned to the orchestrator."""

    requirement: RequirementContext
    market: MarketContext
    universe: UniverseSelection
    features: FeatureBundle
    model: ModelSelectionResult
    strategy_params: StrategyParameters
    portfolio: PortfolioPlan
    execution: ExecutionPlan
    backtest: BacktestSummary


class RequirementService:
    """Handles requirement parsing, parameter mapping and LLM summaries."""

    def __init__(self, system_config: Dict[str, Any]):
        self.system_config = system_config
        self.parser = RequirementParser()
        self.mapper = ParameterMapper()
        self.recommendation_engine = RecommendationEngine()
        self.ai_service: Optional[HybridAIService] = None

        try:
            self.ai_service = HybridAIService(system_config)
        except Exception as exc:  # noqa: BLE001
            LOGGER.warning("HybridAIService unavailable: %s", exc)
            self.ai_service = None

    async def process(self, requirement_text: str) -> RequirementContext:
        LOGGER.info("Parsing user requirement")
        parsed = self.parser.parse_requirement(requirement_text)
        system_params = self.mapper.map_to_system_parameters(parsed)

        user_profile = {
            "risk_tolerance": str(parsed.risk_tolerance),
            "investment_horizon": str(parsed.investment_horizon),
            "goals": [goal.value for goal in parsed.goals]
            if getattr(parsed, "goals", None)
            else ["wealth_growth"],
        }
        market_proxy = {"trend": "neutral", "volatility": "medium"}

        try:
            portfolio_recommendations = (
                self.recommendation_engine.generate_portfolio_recommendations(  # type: ignore[assignment]
                    user_profile=user_profile,
                    market_conditions=market_proxy,
                    num_recommendations=3,
                )
            )
        except Exception as exc:  # noqa: BLE001
            LOGGER.warning("Recommendation engine failed: %s", exc)
            portfolio_recommendations = []

        explanation = await self._build_explanation(parsed, system_params)

        return RequirementContext(
            raw_text=requirement_text,
            parsed_requirement=parsed,
            system_params=system_params,
            portfolio_recommendations=portfolio_recommendations,
            explanation=explanation,
        )

    async def _build_explanation(
        self, parsed_requirement: Any, system_params: Dict[str, Any]
    ) -> Optional[str]:
        summary_lines = [
            "æŠ•èµ„éœ€æ±‚è§£æžç»“æžœ:",
            f"- æŠ•èµ„é‡‘é¢: {getattr(parsed_requirement, 'investment_amount', 'æœªè¯†åˆ«')}",
            f"- é£Žé™©åå¥½: {getattr(parsed_requirement, 'risk_tolerance', 'æœªçŸ¥')}",
            f"- æŠ•èµ„æœŸé™: {getattr(parsed_requirement, 'investment_horizon', 'æœªçŸ¥')}",
        ]
        goals = getattr(parsed_requirement, "goals", None)
        if goals:
            summary_lines.append(
                "- æ ¸å¿ƒç›®æ ‡: " + ", ".join(goal.value for goal in goals)
            )
        if system_params:
            summary_lines.append("- ç³»ç»Ÿå‚æ•°æ˜ å°„: " + ", ".join(system_params.keys()))
        baseline_summary = "\n".join(summary_lines)

        if not self.ai_service:
            return baseline_summary

        try:
            prompt = (
                "è¯·æ ¹æ®ä»¥ä¸‹ç»“æž„åŒ–æŠ•èµ„éœ€æ±‚ï¼Œæ€»ç»“æˆä¸€æ®µä¸“ä¸šå»ºè®®ï¼Œå¹¶å¼ºè°ƒé£Žé™©æŽ§åˆ¶é‡ç‚¹ã€‚"  # noqa: E501
            )
            payload = {
                "ç”¨æˆ·éœ€æ±‚": {
                    "æŠ•èµ„é‡‘é¢": getattr(parsed_requirement, "investment_amount", None),
                    "é£Žé™©åå¥½": getattr(parsed_requirement, "risk_tolerance", None),
                    "æŠ•èµ„æœŸé™": getattr(parsed_requirement, "investment_horizon", None),
                    "ç›®æ ‡": [goal.value for goal in goals] if goals else [],
                },
                "ç³»ç»Ÿå‚æ•°": system_params,
            }
            response = await self.ai_service.chat(  # type: ignore[arg-type]
                user_message=f"{prompt}\næ•°æ®: {payload}",
                conversation_history=None,
            )
            if response.get("success"):
                return response.get("response") or baseline_summary
        except Exception as exc:  # noqa: BLE001
            LOGGER.warning("LLM explanation failed: %s", exc)
        return baseline_summary


class MarketContextService:
    """Derives market regime, sentiment and macro summaries."""

    def __init__(self, rate_limit: float = 0.5):
        self.collector = AkshareDataCollector(rate_limit=rate_limit)
        self.alt_collector = ChineseAlternativeDataCollector(rate_limit=rate_limit)

    async def analyse(self) -> MarketContext:
        LOGGER.info("Analysing market state")
        today = datetime.now()
        end_date = today.strftime("%Y%m%d")
        start_date = (today - timedelta(days=252)).strftime("%Y%m%d")
        index_symbol = "000300"

        try:
            market_df = self.collector.fetch_stock_history(
                index_symbol, start_date, end_date
            )
        except Exception as exc:  # noqa: BLE001
            LOGGER.error("Market data fetch failed: %s", exc)
            market_df = pd.DataFrame()

        regime_data: Dict[str, Any]
        if not market_df.empty:
            detector = MarketRegimeDetector(
                RegimeDetectionConfig(n_regimes=3, use_hmm=True, use_clustering=True)
            )
            try:
                regime_state = detector.detect_market_regime(market_df)
                regime_data = {
                    "state": regime_state.regime.value,
                    "confidence": regime_state.confidence,
                    "characteristics": regime_state.characteristics,
                }
            except Exception as exc:  # noqa: BLE001
                LOGGER.warning("Regime detection failed: %s", exc)
                regime_data = {"state": "neutral", "confidence": 0.5}
        else:
            regime_data = {"state": "neutral", "confidence": 0.5}

        sentiment_data = {"score": 0.0, "confidence": 0.5}
        try:
            sentiment = self.alt_collector.fetch_market_sentiment()
            if isinstance(sentiment, dict):
                sentiment_data = {
                    "score": sentiment.get("market_sentiment", 0.0),
                    "confidence": sentiment.get("confidence", 0.5),
                }
        except Exception as exc:  # noqa: BLE001
            LOGGER.warning("Sentiment fetch failed: %s", exc)

        macro_summary: Dict[str, Any] = {}
        try:
            macro_data = self.alt_collector.fetch_macro_economic_data("all")
            for key, df in macro_data.items():
                if isinstance(df, pd.DataFrame) and not df.empty:
                    latest = df.iloc[-1]
                    macro_summary[key] = {
                        "latest": latest.to_dict()
                        if hasattr(latest, "to_dict")
                        else latest,
                        "records": len(df),
                    }
        except Exception as exc:  # noqa: BLE001
            LOGGER.warning("Macro data fetch failed: %s", exc)

        return MarketContext(
            as_of=today,
            regime=regime_data,
            sentiment=sentiment_data,
            macro_summary=macro_summary,
            data_sources={
                "index": index_symbol,
                "collector": "Akshare",
                "alternative": "ChineseAlternativeDataCollector",
            },
        )


class UniverseService:
    """Builds investable universe from recommendations and filters."""

    def __init__(self):
        self.fundamental_collector = ChineseFundamentalCollector(rate_limit=0.5)

    async def build_universe(
        self,
        requirement_ctx: RequirementContext,
        market_ctx: MarketContext,
    ) -> UniverseSelection:
        LOGGER.info("Selecting investable universe")
        symbols: List[str] = []

        if requirement_ctx.portfolio_recommendations:
            primary_portfolio = requirement_ctx.portfolio_recommendations[0]
            asset_allocation = getattr(primary_portfolio, "asset_allocation", {})
            symbols = self._map_allocation_to_symbols(asset_allocation)
        if not symbols:
            symbols = ["000001", "600036", "000858", "600519", "601318"]

        liquid_symbols: List[str] = []
        liquidity_info: Dict[str, Any] = {}
        for symbol in symbols:
            try:
                financials = self.fundamental_collector.fetch_financial_indicators(
                    symbol
                )
                avg_turnover = financials.get("turnover_ratio") if financials else None
                if avg_turnover is None or avg_turnover >= 5:
                    liquid_symbols.append(symbol)
                    liquidity_info[symbol] = {"turnover_ratio": avg_turnover}
            except Exception as exc:  # noqa: BLE001
                LOGGER.debug("Fundamental fetch failed for %s: %s", symbol, exc)
                liquid_symbols.append(symbol)

        selection_notes = {
            "regime": market_ctx.regime.get("state"),
            "sentiment": market_ctx.sentiment.get("score"),
            "liquidity": liquidity_info,
        }

        return UniverseSelection(
            symbols=liquid_symbols,
            rationale="åŸºäºŽAIæŽ¨èä¸ŽæµåŠ¨æ€§ç­›é€‰çš„è‚¡ç¥¨æ± ",
            selection_notes=selection_notes,
        )

    def _map_allocation_to_symbols(self, allocation: Dict[str, float]) -> List[str]:
        mapping = {
            "stocks": ["600036", "000858", "600519"],
            "dividend_stocks": ["601318", "600028"],
            "growth_stocks": ["000001", "002594"],
            "tech": ["000063", "002475"],
        }
        selected: List[str] = []
        for asset_type, weight in allocation.items():
            bucket = mapping.get(asset_type)
            if bucket and weight > 0:
                quota = max(1, int(round(weight * 10)))
                selected.extend(bucket[:quota])
        if not selected:
            selected = list({code for values in mapping.values() for code in values})
        return list(dict.fromkeys(selected))[:8]


class FeatureEngineeringService:
    """Generates the feature dataset required by downstream models."""

    def __init__(self, rate_limit: float = 0.5):
        self.collector = AkshareDataCollector(rate_limit=rate_limit)
        self.technical = TechnicalIndicators()

    async def prepare(self, universe: UniverseSelection) -> FeatureBundle:
        LOGGER.info("Preparing features for %d symbols", len(universe.symbols))
        today = datetime.now()
        end_date = today.strftime("%Y%m%d")
        start_date = (today - timedelta(days=365)).strftime("%Y%m%d")

        all_features: List[pd.DataFrame] = []
        returns_by_symbol: Dict[str, pd.Series] = {}
        raw_market_data: Dict[str, pd.DataFrame] = {}

        for symbol in universe.symbols:
            try:
                data = self.collector.fetch_stock_history(symbol, start_date, end_date)
                if data is None or data.empty:
                    LOGGER.warning(f"No data for {symbol}")
                    continue

                # ç¡®ä¿æ•°æ®æœ‰æ—¶é—´ç´¢å¼•
                if "date" in data.columns and not isinstance(
                    data.index, pd.DatetimeIndex
                ):
                    data["date"] = pd.to_datetime(data["date"])
                    data.set_index("date", inplace=True)

                raw_market_data[symbol] = data.copy()

                # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
                indicators = self.technical.calculate_all_indicators(data)

                # æ·»åŠ æ›´å¤šç‰¹å¾
                indicators["returns"] = indicators["close"].pct_change()
                indicators["log_returns"] = np.log(
                    indicators["close"] / indicators["close"].shift(1)
                )

                # ä»·æ ¼åŠ¨é‡ç‰¹å¾
                for window in [5, 10, 20]:
                    indicators[f"momentum_{window}"] = indicators["close"].pct_change(
                        window
                    )
                    indicators[f"volatility_{window}"] = (
                        indicators["returns"].rolling(window).std()
                    )

                # æˆäº¤é‡ç‰¹å¾
                if "volume" in indicators.columns:
                    indicators["volume_ma5"] = indicators["volume"].rolling(5).mean()
                    indicators["volume_ratio"] = (
                        indicators["volume"] / indicators["volume_ma5"]
                    )

                # æœªæ¥æ”¶ç›Šï¼ˆé¢„æµ‹ç›®æ ‡ï¼‰
                indicators["future_returns"] = indicators["returns"].shift(-1)

                # æ·»åŠ è‚¡ç¥¨æ ‡è¯†
                indicators["symbol"] = symbol

                # æ¸…ç†æ•°æ®
                indicators = indicators.replace([np.inf, -np.inf], np.nan)
                indicators = indicators.dropna()

                if not indicators.empty and len(indicators) > 20:
                    all_features.append(indicators)
                    returns_by_symbol[symbol] = indicators["returns"].copy().dropna()
                    LOGGER.info(
                        f"âœ“ {symbol}: {len(indicators)} records with {len(indicators.columns)} features"
                    )
                else:
                    LOGGER.warning(
                        f"Insufficient data for {symbol}: {len(indicators)} records"
                    )

            except Exception as exc:  # noqa: BLE001
                LOGGER.warning("Feature preparation failed for %s: %s", symbol, exc)

        if not all_features:
            raise RuntimeError("No feature data available for the selected universe")

        combined = pd.concat(all_features, ignore_index=True)
        train_size = int(0.8 * len(combined))
        train_data = combined.iloc[:train_size].copy()

        return FeatureBundle(
            combined_features=combined,
            train_data=train_data,
            returns_by_symbol=returns_by_symbol,
            raw_market_data=raw_market_data,
            prepared_at=today,
        )


class ModelService:
    """Selects, trains and returns the predictive model."""

    def select_model(self, market_ctx: MarketContext) -> ModelChoice:
        state = market_ctx.regime.get("state", "neutral")
        sentiment = market_ctx.sentiment.get("score", 0.0)

        if state == "bull":
            return ModelChoice(
                model_type="lstm",
                config={
                    "sequence_length": 10,
                    "hidden_size": 64,
                    "num_layers": 2,
                    "epochs": 15,
                },
                reason="ç‰›å¸‚çŽ¯å¢ƒä¸‹ä½¿ç”¨LSTMæ•æ‰è¶‹åŠ¿",
            )
        if state == "bear":
            return ModelChoice(
                model_type="online",
                config={"learning_rate": 0.01, "buffer_size": 500},
                reason="ç†Šå¸‚éœ€è¦å¿«é€Ÿé€‚åº”çš„åœ¨çº¿å­¦ä¹ æ¨¡åž‹",
            )
        if abs(sentiment) > 0.5:
            return ModelChoice(
                model_type="ppo",
                config={"learning_rate": 0.0003, "hidden_dims": [64, 64]},
                reason="æƒ…ç»ªæžç«¯æ—¶é‡‡ç”¨å¼ºåŒ–å­¦ä¹ è¿›è¡Œå†³ç­–",
            )
        return ModelChoice(
            model_type="ensemble",
            config={"models": ["lstm", "transformer"], "voting": "weighted"},
            reason="éœ‡è¡å¸‚é‡‡ç”¨é›†æˆæ¨¡åž‹æå‡ç¨³å®šæ€§",
        )

    async def train_model(
        self,
        choice: ModelChoice,
        feature_bundle: FeatureBundle,
    ) -> ModelSelectionResult:
        LOGGER.info("Training %s model", choice.model_type.upper())
        metadata: Dict[str, Any] = {}

        if choice.model_type == "lstm":
            model, metrics = await self._train_lstm(
                choice.config, feature_bundle.train_data
            )
        elif choice.model_type == "online":
            model, metrics = await self._train_online(
                choice.config, feature_bundle.train_data
            )
        elif choice.model_type == "ppo":
            model, metrics = await self._train_ppo(
                choice.config, feature_bundle.train_data
            )
        elif choice.model_type == "ensemble":
            model, metrics = await self._train_ensemble(
                choice.config, feature_bundle.train_data
            )
        else:
            model, metrics = await self._train_lstm(
                choice.config, feature_bundle.train_data
            )

        metadata.update(metrics)

        return ModelSelectionResult(
            choice=choice, model=model, training_metadata=metadata
        )

    async def _train_lstm(
        self,
        config: Dict[str, Any],
        train_data: pd.DataFrame,
    ) -> Any:
        LOGGER.info("ðŸ”§ Preparing LSTM training data...")

        # ç¡®ä¿future_returnså­˜åœ¨
        if "future_returns" not in train_data.columns:
            LOGGER.warning("future_returns not found, calculating...")
            train_data = train_data.copy()
            train_data["future_returns"] = (
                train_data.groupby("symbol")["close"].pct_change(5).shift(-5)
            )

        # æ¸…ç†æ•°æ®ï¼šç§»é™¤NaNå’ŒInf
        train_data = train_data.replace([np.inf, -np.inf], np.nan)
        train_data = train_data.dropna(subset=["future_returns"])

        # æ•°å€¼åŒ–æ‰€æœ‰ç‰¹å¾
        feature_cols = [
            c
            for c in train_data.columns
            if c not in ["symbol", "date", "future_returns"]
        ]
        train_data[feature_cols] = (
            train_data[feature_cols].apply(pd.to_numeric, errors="coerce").fillna(0)
        )

        LOGGER.info(
            f"âœ… Training data prepared: {len(train_data)} samples, {len(feature_cols)} features"
        )

        lstm_config = LSTMModelConfig(
            sequence_length=config.get("sequence_length", 10),
            hidden_size=config.get("hidden_size", 50),  # å¢žåŠ éšè—å±‚
            num_layers=config.get("num_layers", 2),
            epochs=config.get("epochs", 50),  # å¢žåŠ è®­ç»ƒè½®æ¬¡
            batch_size=32,
            learning_rate=0.001,
            dropout=0.2,
        )
        model = LSTMModel(lstm_config)

        try:
            X, y = model.prepare_data(
                train_data.drop(columns=["symbol"], errors="ignore"), "future_returns"
            )
            LOGGER.info(f"ðŸŽ¯ Training LSTM model: X shape={X.shape}, y shape={y.shape}")
            metrics = model.train(X, y)

            # éªŒè¯æ¨¡åž‹
            test_pred = model.predict(X[:10])
            LOGGER.info(f"âœ… Model validation: predictions={test_pred[:5]}")
            LOGGER.info(f"âœ… Training metrics: {metrics}")

            return model, {"training_metrics": metrics, "data_shape": X.shape}
        except Exception as e:
            LOGGER.error(f"âŒ LSTM training failed: {e}", exc_info=True)
            # è¿”å›žä¸€ä¸ªç®€å•çš„fallbackæ¨¡åž‹
            return model, {"training_metrics": {"error": str(e)}}

    async def _train_online(
        self,
        config: Dict[str, Any],
        train_data: pd.DataFrame,
    ) -> Any:
        online_config = OnlineLearningConfig(
            learning_rate=config.get("learning_rate", 0.01),
            buffer_size=config.get("buffer_size", 500),
        )
        model = OnlineLearner(online_config)
        features = train_data.drop(
            columns=["symbol", "future_returns"], errors="ignore"
        ).values
        targets = train_data["future_returns"].values
        for feat, target in zip(features[:1000], targets[:1000]):
            model.add_sample(feat, float(target))
        return model, {"training_samples": min(len(features), 1000)}

    async def _train_ppo(
        self,
        config: Dict[str, Any],
        train_data: pd.DataFrame,
    ) -> Any:
        ppo_config = PPOConfig(
            state_dim=config.get("state_dim", 10),
            action_dim=config.get("action_dim", 3),
            learning_rate=config.get("learning_rate", 0.0003),
            hidden_dims=config.get("hidden_dims", [64, 64]),
        )
        model = PPOAgent(ppo_config)
        return model, {
            "training_notice": "Placeholder training - requires environment integration"
        }

    async def _train_ensemble(
        self,
        config: Dict[str, Any],
        train_data: pd.DataFrame,
    ) -> Any:
        LOGGER.info("ðŸ”§ Training Ensemble model...")

        # ç¡®ä¿æ•°æ®æ¸…æ´
        if "future_returns" not in train_data.columns:
            train_data = train_data.copy()
            train_data["future_returns"] = (
                train_data.groupby("symbol")["close"].pct_change(5).shift(-5)
            )

        train_data = train_data.replace([np.inf, -np.inf], np.nan)
        train_data = train_data.dropna(subset=["future_returns"])

        # æ•°å€¼åŒ–
        feature_cols = [
            c
            for c in train_data.columns
            if c not in ["symbol", "date", "future_returns"]
        ]
        train_data[feature_cols] = (
            train_data[feature_cols].apply(pd.to_numeric, errors="coerce").fillna(0)
        )

        # è®­ç»ƒåŸºç¡€LSTMæ¨¡åž‹
        base_model, lstm_metrics = await self._train_lstm({}, train_data)

        # æž„å»ºé›†æˆæ¨¡åž‹
        ensemble_config = EnsembleConfig(
            models=[{"name": "lstm", "model": base_model, "weight": 1.0}],
            voting_strategy=config.get("voting", "weighted"),
        )
        ensemble = EnsemblePredictor(ensemble_config)

        # å°è¯•è®­ç»ƒensembleï¼ˆå¦‚æžœæœ‰trainæ–¹æ³•ï¼‰
        try:
            if hasattr(ensemble, "train"):
                X = train_data[feature_cols].values
                y = train_data["future_returns"].values
                ensemble.train(X, y)
                LOGGER.info("âœ… Ensemble model trained")
        except Exception as e:
            LOGGER.warning(f"Ensemble training skipped: {e}")

        return ensemble, {
            "base_model_metrics": lstm_metrics,
            "ensemble_models": len(ensemble_config.models),
        }


class StrategyDesignService:
    """Translates market state and risk appetite into trading parameters."""

    def build_parameters(self, market_ctx: MarketContext) -> StrategyParameters:
        state = market_ctx.regime.get("state", "neutral")
        if state == "bull":
            return StrategyParameters(
                buy_threshold=0.001,
                confidence_threshold=0.5,
                max_position=0.4,
                style="bullish",
            )
        if state == "bear":
            return StrategyParameters(
                buy_threshold=0.003,
                confidence_threshold=0.7,
                max_position=0.2,
                style="defensive",
            )
        return StrategyParameters(
            buy_threshold=0.002,
            confidence_threshold=0.6,
            max_position=0.3,
            style="balanced",
        )


class PortfolioService:
    """Builds the target portfolio using risk-aware optimisation."""

    def __init__(self):
        config = MVOConfig(objective=OptimizationObjective.MAX_SHARPE)
        self.optimizer = MeanVarianceOptimizer(config)

    def construct_portfolio(
        self,
        feature_bundle: FeatureBundle,
        strategy_params: StrategyParameters,
        initial_capital: float,
    ) -> PortfolioPlan:
        LOGGER.info("Constructing portfolio via mean-variance optimisation")
        returns_df = pd.DataFrame(feature_bundle.returns_by_symbol)
        returns_df = returns_df.dropna()
        if returns_df.empty:
            weights = {
                symbol: 1.0 / len(feature_bundle.returns_by_symbol)
                for symbol in feature_bundle.returns_by_symbol
            }
            risk_metrics = {
                "note": "Insufficient data for optimisation; fallback to equal weight"
            }
            return PortfolioPlan(
                weights=weights,
                cash_buffer=initial_capital * 0.05,
                risk_metrics=risk_metrics,
            )

        expected_returns = returns_df.mean()
        cov_matrix = returns_df.cov()
        result = self.optimizer.optimize_portfolio(expected_returns, cov_matrix)
        weights = dict(zip(result.asset_names, result.weights))

        cash_buffer = initial_capital * 0.05
        risk_metrics = {
            "expected_return": result.expected_return,
            "expected_volatility": result.expected_volatility,
            "sharpe_ratio": result.sharpe_ratio,
            "max_drawdown_estimate": result.max_drawdown_estimate,
            "var_95": result.var_95,
            "cvar_95": result.cvar_95,
            "strategy_style": strategy_params.style,
        }

        return PortfolioPlan(
            weights=weights, cash_buffer=cash_buffer, risk_metrics=risk_metrics
        )


class ExecutionPlanningService:
    """Transforms portfolio targets into execution-ready orders."""

    def __init__(self):
        self.filter = SignalFilter(FilterConfig(min_signal_strength=0.5))
        self.order_manager = OrderManager()

    def build_plan(
        self,
        portfolio: PortfolioPlan,
        feature_bundle: FeatureBundle,
        strategy_params: StrategyParameters,
        initial_capital: float,
    ) -> ExecutionPlan:
        LOGGER.info("Building execution plan")
        total_capital = initial_capital - portfolio.cash_buffer
        orders: List[Dict[str, Any]] = []

        for symbol, weight in portfolio.weights.items():
            market_data = feature_bundle.raw_market_data.get(symbol)
            if market_data is None or market_data.empty:
                continue
            latest_price = float(market_data["close"].iloc[-1])
            allocation_capital = total_capital * max(weight, 0)
            if allocation_capital <= 0 or latest_price <= 0:
                continue
            quantity = int(allocation_capital / latest_price / 100) * 100
            if quantity <= 0:
                continue
            signal = Signal(
                signal_id=f"plan_{symbol}_{datetime.now().strftime('%Y%m%d%H%M%S')}",
                symbol=symbol,
                action="BUY",
                price=latest_price,
                quantity=quantity,
                confidence=max(strategy_params.confidence_threshold, 0.6),
                timestamp=datetime.now(),
                strategy_name="æ™ºèƒ½AIç­–ç•¥",
                metadata={"weight": weight},
            )
            order = self.order_manager.create_order_from_signal(signal)
            orders.append(
                {
                    "order_id": order.order_id,
                    "symbol": symbol,
                    "side": order.side,
                    "quantity": order.quantity,
                    "price": order.price,
                    "destination": ExecutionDestination.EXCHANGE.value,
                }
            )

        notes = "é»˜è®¤é‡‡ç”¨TWAPé£Žæ ¼åˆ‡ç‰‡æ‰§è¡Œï¼Œå¯ä¾æ®å®žæ—¶æµåŠ¨æ€§åŠ¨æ€è°ƒæ•´ã€‚"

        return ExecutionPlan(orders=orders, algorithm="TWAP", notes=notes)


class BacktestService:
    """Runs backtests and aggregates reports."""

    def __init__(self):
        self.performance_analyzer = PerformanceAnalyzer()
        self.code_generator = StrategyCodeGenerator()
        # æ–°å¢žï¼šè‡ªé€‚åº”å‚æ•°ç®¡ç†å™¨å’Œé£Žé™©æŽ§åˆ¶å™¨
        from ai_strategy_system.core.enhanced_strategy_generator import (
            create_enhanced_strategy_generator,
        )
        from ai_strategy_system.services.adaptive_parameter_manager import (
            create_adaptive_parameter_manager,
        )
        from ai_strategy_system.services.risk_controller import create_risk_controller

        self.param_manager = create_adaptive_parameter_manager()
        self.risk_controller = create_risk_controller()
        self.enhanced_generator = (
            create_enhanced_strategy_generator()
        )  # å¢žå¼ºç‰ˆç­–ç•¥ç”Ÿæˆå™¨

    async def run_backtest(
        self,
        feature_bundle: FeatureBundle,
        execution_plan: ExecutionPlan,
        trained_model: ModelSelectionResult,
        strategy_params: StrategyParameters,
        initial_capital: float,
        market_context: Optional[Any] = None,
        risk_level: str = "MODERATE",
    ) -> BacktestSummary:
        LOGGER.info("Running backtest")
        today = datetime.now()
        start_date = today - timedelta(days=365)

        config = BacktestConfig(
            start_date=start_date,
            end_date=today,
            initial_capital=initial_capital,
            commission_rate=0.0003,
            slippage_bps=5.0,
            save_to_db=True,
            strategy_name=f"æ™ºèƒ½AIç­–ç•¥-{trained_model.choice.model_type.upper()}",
        )

        # ä¼ å…¥é£Žé™©æŽ§åˆ¶å™¨
        engine = BacktestEngine(config, risk_controller=self.risk_controller)
        symbols = list(feature_bundle.raw_market_data.keys())
        engine.load_market_data(symbols, feature_bundle.raw_market_data)
        LOGGER.info("âœ… é£Žé™©æŽ§åˆ¶å™¨å·²é›†æˆåˆ°å›žæµ‹å¼•æ“Ž")

        # === æ–°å¢žï¼šä½¿ç”¨è‡ªé€‚åº”å‚æ•°ç®¡ç†å™¨ ===
        market_context_dict = None
        if market_context:
            market_context_dict = {
                "regime": market_context.regime
                if hasattr(market_context, "regime")
                else {},
                "volatility": market_context.volatility
                if hasattr(market_context, "volatility")
                else 0.02,
            }

        adaptive_params = self.param_manager.adjust_parameters(
            market_context=market_context_dict,
            backtest_performance=None,  # é¦–æ¬¡å›žæµ‹æ— åŽ†å²æ•°æ®
            risk_level=risk_level,
        )

        LOGGER.info("âœ¨ ä½¿ç”¨è‡ªé€‚åº”å‚æ•°:")
        LOGGER.info(f"   ä¹°å…¥é˜ˆå€¼: {adaptive_params['buy_threshold']:.4f}")
        LOGGER.info(f"   å–å‡ºé˜ˆå€¼: {adaptive_params['sell_threshold']:.4f}")
        LOGGER.info(f"   ç½®ä¿¡åº¦: {adaptive_params['confidence_threshold']:.2f}")
        LOGGER.info(f"   æœ€å¤§ä»“ä½: {adaptive_params['max_position']:.2f}")
        LOGGER.info(
            f"   è°ƒæ•´åŽŸå› : {adaptive_params.get('reason', 'No reason provided')}"
        )

        # ç”Ÿæˆå¯æ‰§è¡Œçš„ç­–ç•¥ä»£ç 
        feature_columns = [
            col
            for col in feature_bundle.combined_features.columns
            if col not in ["symbol", "future_returns", "date"]
        ]

        # ä½¿ç”¨å¢žå¼ºç‰ˆç­–ç•¥ç”Ÿæˆå™¨ï¼ˆå¤šé‡ä¿¡å·ç¡®è®¤ï¼‰
        model_type = trained_model.choice.model_type
        if model_type in ["lstm", "ensemble"]:
            LOGGER.info(f"ðŸš€ ä½¿ç”¨å¢žå¼ºç‰ˆ{model_type.upper()}ç­–ç•¥ï¼ˆå¤šé‡ä¿¡å·ç¡®è®¤ï¼‰")
            strategy_params = {
                "buy_threshold": adaptive_params["buy_threshold"],
                "sell_threshold": adaptive_params["sell_threshold"],
                "confidence_threshold": adaptive_params["confidence_threshold"],
                "max_position": adaptive_params["max_position"],
                "sequence_length": 10,
            }

            if model_type == "lstm":
                strategy_code = self.enhanced_generator.generate_enhanced_lstm_strategy(
                    model=trained_model.model,
                    params=strategy_params,
                    features=feature_columns,
                )
            else:  # ensemble
                strategy_code = (
                    self.enhanced_generator.generate_enhanced_ensemble_strategy(
                        model=trained_model.model,
                        params=strategy_params,
                        features=feature_columns,
                    )
                )
        else:
            # PPOå’Œå…¶ä»–æ¨¡åž‹ä½¿ç”¨åŽŸæ¥çš„ç”Ÿæˆå™¨
            LOGGER.info(f"ä½¿ç”¨æ ‡å‡†{model_type.upper()}ç­–ç•¥")
            strategy_code = self.code_generator.generate_strategy_code(
                model_type=model_type,
                model_instance=trained_model.model,
                strategy_params={
                    "buy_threshold": adaptive_params["buy_threshold"],
                    "sell_threshold": adaptive_params["sell_threshold"],
                    "confidence_threshold": adaptive_params["confidence_threshold"],
                    "max_position": adaptive_params["max_position"],
                    "sequence_length": 10,
                    "max_drawdown_limit": adaptive_params.get(
                        "max_drawdown_limit", 0.15
                    ),
                    "daily_loss_limit": adaptive_params.get("daily_loss_limit", 0.03),
                },
                feature_columns=feature_columns,
            )

        LOGGER.info(f"Generated strategy code: {strategy_code.strategy_name}")

        # ä½¿ç”¨ç”Ÿæˆçš„ç­–ç•¥å‡½æ•°
        # ç¼“å­˜ç‰¹å¾æ•°æ®ä»¥ä¾›ç­–ç•¥ä½¿ç”¨
        combined_features = feature_bundle.combined_features.copy()

        def strategy_wrapper(
            current_data: Dict[str, pd.Series],
            positions: Dict[str, Any],
            capital: float,
        ) -> List[Signal]:
            """ç­–ç•¥åŒ…è£…å™¨ï¼Œä¼ å…¥ç‰¹å¾æ•°æ®"""
            try:
                LOGGER.debug(
                    f"Strategy called with {len(current_data)} symbols, capital={capital:.2f}"
                )
                signals = strategy_code.strategy_function(
                    current_data=current_data,
                    positions=positions,
                    capital=capital,
                    feature_data=combined_features,
                )
                if signals:
                    LOGGER.info(f"âœ… Generated {len(signals)} signals")
                return signals
            except Exception as e:
                LOGGER.error(f"Strategy function error: {e}", exc_info=True)
                return []

        engine.set_strategy(strategy_wrapper)
        result = engine.run()

        if "equity" in result.equity_curve.columns:
            returns = result.equity_curve["equity"].pct_change().dropna()
        else:
            returns = pd.Series(dtype=float)
        result.daily_returns = returns
        if not returns.empty:
            cumulative = (1 + returns).cumprod()
            drawdown = cumulative / cumulative.cummax() - 1
            result.drawdown_series = drawdown
            perf_report = self.performance_analyzer.analyze(returns=returns)
        else:
            LOGGER.warning("å›žæµ‹æ”¶ç›Šåºåˆ—ä¸ºç©ºï¼Œè·³è¿‡æ€§èƒ½åˆ†æž")
            result.drawdown_series = pd.Series(dtype=float)
            perf_report = None

        report_config = ReportConfig(
            title=f"æ™ºèƒ½AIç­–ç•¥å›žæµ‹æŠ¥å‘Š - {trained_model.choice.model_type.upper()}",
            formats=["html"],
            output_dir="reports",
        )
        report_gen = BacktestReportGenerator(report_config)
        try:
            report_files = report_gen.generate_report(backtest_result=result)
        except Exception as exc:  # noqa: BLE001
            LOGGER.warning("æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {}", exc)
            report_files = {}

        backtest_id = getattr(engine, "backtest_id", None)

        # === æ–°å¢žï¼šä¿å­˜ç­–ç•¥åˆ°æ–‡ä»¶ç³»ç»Ÿ ===
        strategy_id = None
        try:
            from ai_strategy_system.utils.strategy_persistence import (
                create_strategy_persistence,
            )

            persistence = create_strategy_persistence()
            strategy_id = persistence.save_strategy(
                strategy_code=strategy_code,
                trained_model=trained_model.model,
                config={
                    "model_type": trained_model.choice.model_type,
                    "backtest_id": backtest_id,
                    "training_config": {
                        "start_date": config.start_date.isoformat()
                        if hasattr(config.start_date, "isoformat")
                        else str(config.start_date),
                        "end_date": config.end_date.isoformat()
                        if hasattr(config.end_date, "isoformat")
                        else str(config.end_date),
                        "initial_capital": config.initial_capital,
                    },
                },
                backtest_result=result,
                user_requirement=None,  # ä»Žéœ€æ±‚ä¸Šä¸‹æ–‡èŽ·å–ï¼ˆå¦‚æžœæœ‰ï¼‰
            )

            LOGGER.info(f"ðŸ“ ç­–ç•¥å·²æŒä¹…åŒ–ï¼ŒID: {strategy_id}")
            LOGGER.info(
                f"ðŸ“ ç­–ç•¥è·¯å¾„: ai_strategy_system/generated_strategies/{strategy_id}/"
            )

        except Exception as e:
            LOGGER.warning(f"âš ï¸  ç­–ç•¥æŒä¹…åŒ–å¤±è´¥: {e}")

        return BacktestSummary(
            result=result,
            performance_report=perf_report,
            report_files=report_files,
            backtest_id=backtest_id,
            strategy_code=strategy_code,
            strategy_id=strategy_id,  # æ–°å¢žï¼šè¿”å›žç­–ç•¥ID
        )


class StrategyWorkflow:
    """Coordinates the end-to-end workflow through service composition."""

    def __init__(self):
        config_loader = ConfigLoader()
        self.system_config = config_loader.load_system_config()
        self.requirement_service = RequirementService(self.system_config)
        self.market_service = MarketContextService()
        self.universe_service = UniverseService()
        self.feature_service = FeatureEngineeringService()
        self.model_service = ModelService()
        self.strategy_service = StrategyDesignService()
        self.portfolio_service = PortfolioService()
        self.execution_service = ExecutionPlanningService()
        self.backtest_service = BacktestService()

    async def run(
        self,
        requirement_text: str,
        initial_capital: float,
    ) -> StrategyWorkflowResult:
        requirement_ctx = await self.requirement_service.process(requirement_text)
        market_ctx = await self.market_service.analyse()
        universe = await self.universe_service.build_universe(
            requirement_ctx, market_ctx
        )
        feature_bundle = await self.feature_service.prepare(universe)
        model_choice = self.model_service.select_model(market_ctx)
        trained_model = await self.model_service.train_model(
            model_choice, feature_bundle
        )
        strategy_params = self.strategy_service.build_parameters(market_ctx)
        portfolio_plan = self.portfolio_service.construct_portfolio(
            feature_bundle, strategy_params, initial_capital
        )
        execution_plan = self.execution_service.build_plan(
            portfolio_plan, feature_bundle, strategy_params, initial_capital
        )

        # èŽ·å–é£Žé™©ç­‰çº§
        risk_level = "MODERATE"
        if requirement_ctx and hasattr(requirement_ctx, "parsed_requirement"):
            parsed = requirement_ctx.parsed_requirement
            if hasattr(parsed, "risk_tolerance") and parsed.risk_tolerance:
                risk_level = parsed.risk_tolerance.value.upper()

        backtest_summary = await self.backtest_service.run_backtest(
            feature_bundle,
            execution_plan,
            trained_model,
            strategy_params,
            initial_capital,
            market_context=market_ctx,
            risk_level=risk_level,
        )

        return StrategyWorkflowResult(
            requirement=requirement_ctx,
            market=market_ctx,
            universe=universe,
            features=feature_bundle,
            model=trained_model,
            strategy_params=strategy_params,
            portfolio=portfolio_plan,
            execution=execution_plan,
            backtest=backtest_summary,
        )


async def run_strategy_workflow(
    requirement_text: str, initial_capital: float
) -> StrategyWorkflowResult:
    """Convenience coroutine for executing the full workflow."""
    workflow = StrategyWorkflow()
    return await workflow.run(requirement_text, initial_capital)
