#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Module 02 ç‰¹å¾å·¥ç¨‹æ¨¡å—æµ‹è¯•
æµ‹è¯•æŠ€æœ¯æŒ‡æ ‡è®¡ç®—ã€å› å­åˆ†æã€æ—¶é—´åºåˆ—ç‰¹å¾ã€å›¾ç‰¹å¾åˆ†æç­‰åŠŸèƒ½
"""

import os
import sys
from datetime import datetime, timedelta

# è®¾ç½® Windows æ§åˆ¶å° UTF-8 ç¼–ç æ”¯æŒ
if sys.platform == "win32":
    import codecs
    sys.stdout = codecs.getwriter("utf-8")(sys.stdout.detach())
    sys.stderr = codecs.getwriter("utf-8")(sys.stderr.detach())

import numpy as np
import pandas as pd
import pytest

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from module_01_data_pipeline import AkshareDataCollector, get_database_manager
from module_02_feature_engineering import (
    GRAPH_EMBEDDINGS_AVAILABLE,
    FactorAnalyzer,
    FeatureCacheManager,
    GraphAnalyzer,
    TechnicalIndicators,
    TimeSeriesFeatures,
    calculate_technical_indicators,
    get_feature_database_manager,
)

# æ ¹æ®å¯ç”¨æ€§å¯¼å…¥å›¾åµŒå…¥åŠŸèƒ½
if GRAPH_EMBEDDINGS_AVAILABLE:
    from module_02_feature_engineering import (
        GraphEmbeddingExtractor,
        extract_graph_features,
    )


def test_basic_setup():
    """æµ‹è¯•åŸºæœ¬ç¯å¢ƒè®¾ç½®"""
    print("=" * 50)
    print("ğŸ§ª æµ‹è¯• 1: åŸºæœ¬ç¯å¢ƒè®¾ç½®")
    print("=" * 50)

    try:
        # æµ‹è¯•æ¨¡å—å¯¼å…¥
        calculator = TechnicalIndicators()
        analyzer = FactorAnalyzer()
        ts_extractor = TimeSeriesFeatures()
        graph_analyzer = GraphAnalyzer()

        print("âœ… æ‰€æœ‰æ ¸å¿ƒç±»å¯¼å…¥æˆåŠŸ")

        # æµ‹è¯•æ•°æ®åº“è¿æ¥
        feature_db = get_feature_database_manager()
        stats = feature_db.get_database_stats()
        print(
            f"âœ… ç‰¹å¾æ•°æ®åº“è¿æ¥æˆåŠŸï¼Œå½“å‰å¤§å°: {stats.get('database_size_mb', 0):.2f} MB"
        )

        # æµ‹è¯•ç¼“å­˜ç³»ç»Ÿ
        cache = FeatureCacheManager(max_size=100, ttl=300)
        cache.set("test", "symbol", {"test": "data"})
        cached_data = cache.get("test", "symbol")
        assert cached_data is not None
        print("âœ… ç¼“å­˜ç³»ç»Ÿå·¥ä½œæ­£å¸¸")

        return True

    except Exception as e:
        print(f"âŒ åŸºæœ¬ç¯å¢ƒè®¾ç½®å¤±è´¥: {e}")
        return False


def test_data_loading():
    """æµ‹è¯•ä»Module01åŠ è½½æ•°æ®"""
    print("\n" + "=" * 50)
    print("ğŸ§ª æµ‹è¯• 2: æ•°æ®åŠ è½½")
    print("=" * 50)

    try:
        # è·å–æ•°æ®æ”¶é›†å™¨
        collector = AkshareDataCollector(rate_limit=1.0)

        # æµ‹è¯•è‚¡ç¥¨åˆ—è¡¨
        symbols = ["000001", "600036"]  # å¹³å®‰é“¶è¡Œã€æ‹›å•†é“¶è¡Œ
        end_date = datetime.now().strftime("%Y%m%d")
        start_date = (datetime.now() - timedelta(days=30)).strftime("%Y%m%d")

        stock_data = {}

        for symbol in symbols:
            try:
                data = collector.fetch_stock_history(symbol, start_date, end_date)
                if not data.empty and len(data) > 10:
                    stock_data[symbol] = data
                    print(f"âœ… {symbol}: åŠ è½½äº† {len(data)} æ¡è®°å½•")
                else:
                    print(f"âš ï¸ {symbol}: æ•°æ®ä¸è¶³")
            except Exception as e:
                print(f"âš ï¸ {symbol}: åŠ è½½å¤±è´¥ - {e}")

        if len(stock_data) == 0:
            print("âš ï¸ ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®è¿›è¡Œæµ‹è¯•")
            # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
            dates = pd.date_range(start=start_date, end=end_date, freq="D")[:20]
            for symbol in symbols:
                mock_data = pd.DataFrame(
                    {
                        "open": np.random.randn(len(dates)).cumsum() + 100,
                        "high": np.random.randn(len(dates)).cumsum() + 105,
                        "low": np.random.randn(len(dates)).cumsum() + 95,
                        "close": np.random.randn(len(dates)).cumsum() + 100,
                        "volume": np.random.randint(1000000, 10000000, len(dates)),
                    },
                    index=dates,
                )
                stock_data[symbol] = mock_data
                print(f"âœ… {symbol}: ç”Ÿæˆäº† {len(mock_data)} æ¡æ¨¡æ‹Ÿæ•°æ®")

        return stock_data

    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return {}


@pytest.fixture(scope="session")
def stock_data():
    """è‚¡ç¥¨æ•°æ®çš„fixture"""
    # è¿”å›æ•°æ®åŠ è½½çš„ç»“æœ
    return test_data_loading()


def test_technical_indicators(stock_data):
    """æµ‹è¯•æŠ€æœ¯æŒ‡æ ‡è®¡ç®—"""
    print("\n" + "=" * 50)
    print("ğŸ§ª æµ‹è¯• 3: æŠ€æœ¯æŒ‡æ ‡è®¡ç®—")
    print("=" * 50)

    if not stock_data:
        print("âŒ æ— æ•°æ®å¯æµ‹è¯•")
        return False

    try:
        calculator = TechnicalIndicators()
        feature_db = get_feature_database_manager()

        success_count = 0

        for symbol, data in stock_data.items():
            try:
                # æµ‹è¯•å•ä¸ªæŒ‡æ ‡è®¡ç®—
                sma20 = calculator.calculate_sma(data["close"], 20)
                rsi = calculator.calculate_rsi(data["close"])
                macd_data = calculator.calculate_macd(data["close"])

                print(f"âœ… {symbol}: å•ä¸ªæŒ‡æ ‡è®¡ç®—æˆåŠŸ")
                print(f"   - SMA20 æœ€æ–°å€¼: {sma20.iloc[-1]:.2f}")
                print(f"   - RSI æœ€æ–°å€¼: {rsi.iloc[-1]:.2f}")
                print(f"   - MACD åŒ…å« {len(macd_data)} ä¸ªç»„ä»¶")

                # æµ‹è¯•æ‰¹é‡æŒ‡æ ‡è®¡ç®—
                all_indicators = calculator.calculate_all_indicators(data)
                original_cols = len(data.columns)
                new_cols = len(all_indicators.columns)

                print(f"âœ… {symbol}: æ‰¹é‡æŒ‡æ ‡è®¡ç®—æˆåŠŸ")
                print(
                    f"   - åŸå§‹åˆ—æ•°: {original_cols}, æ–°å¢æŒ‡æ ‡: {new_cols - original_cols}"
                )

                # æµ‹è¯•æ•°æ®åº“ä¿å­˜
                if feature_db.save_technical_indicators(symbol, all_indicators):
                    print(f"âœ… {symbol}: æŠ€æœ¯æŒ‡æ ‡å·²ä¿å­˜åˆ°æ•°æ®åº“")
                    success_count += 1
                else:
                    print(f"âš ï¸ {symbol}: æ•°æ®åº“ä¿å­˜å¤±è´¥")

                # æµ‹è¯•æ•°æ®åº“æŸ¥è¯¢
                saved_indicators = feature_db.get_technical_indicators(symbol)
                if not saved_indicators.empty:
                    print(
                        f"âœ… {symbol}: ä»æ•°æ®åº“æŸ¥è¯¢åˆ° {saved_indicators.shape} çš„æŒ‡æ ‡æ•°æ®"
                    )

            except Exception as e:
                print(f"âŒ {symbol}: æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å¤±è´¥ - {e}")

        # æµ‹è¯•ä¾¿æ·å‡½æ•°
        symbol = list(stock_data.keys())[0]
        data = stock_data[symbol]
        quick_indicators = calculate_technical_indicators(data)
        print(f"âœ… ä¾¿æ·å‡½æ•°æµ‹è¯•æˆåŠŸï¼Œè®¡ç®—äº† {quick_indicators.shape[1]} ä¸ªæŒ‡æ ‡")

        return success_count > 0

    except Exception as e:
        print(f"âŒ æŠ€æœ¯æŒ‡æ ‡æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_factor_analysis(stock_data):
    """æµ‹è¯•å› å­åˆ†æ"""
    print("\n" + "=" * 50)
    print("ğŸ§ª æµ‹è¯• 4: å› å­åˆ†æ")
    print("=" * 50)

    if not stock_data:
        print("âŒ æ— æ•°æ®å¯æµ‹è¯•")
        return False

    try:
        analyzer = FactorAnalyzer()
        calculator = TechnicalIndicators()
        feature_db = get_feature_database_manager()

        success_count = 0

        for symbol, data in stock_data.items():
            try:
                # è®¡ç®—æ”¶ç›Šç‡
                returns = data["close"].pct_change().dropna()

                if len(returns) < 10:
                    print(f"âš ï¸ {symbol}: æ•°æ®ä¸è¶³ï¼Œè·³è¿‡å› å­åˆ†æ")
                    continue

                # è®¡ç®—RSIä½œä¸ºæµ‹è¯•å› å­
                rsi = calculator.calculate_rsi(data["close"])

                # å¯¹é½æ•°æ®
                common_index = rsi.index.intersection(returns.index)
                if len(common_index) < 5:
                    print(f"âš ï¸ {symbol}: å¯¹é½åæ•°æ®ä¸è¶³")
                    continue

                rsi_aligned = rsi.loc[common_index]
                returns_aligned = returns.loc[common_index]

                # å› å­åˆ†æ
                factor_result = analyzer.analyze_factor(rsi_aligned, returns_aligned)

                print(f"âœ… {symbol}: å› å­åˆ†æå®Œæˆ")
                print(f"   - IC: {factor_result.ic:.4f}")
                print(f"   - Rank IC: {factor_result.rank_ic:.4f}")
                print(f"   - IR: {factor_result.ir:.4f}")

                # ä¿å­˜å› å­æ•°æ®
                factor_id = f"rsi_factor_{symbol}"
                if feature_db.save_factor_data(
                    factor_id, symbol, rsi_aligned, "technical"
                ):
                    print(f"âœ… {symbol}: å› å­æ•°æ®å·²ä¿å­˜")
                    success_count += 1

                # æŸ¥è¯¢å› å­æ•°æ®
                saved_factor = feature_db.get_factor_data(factor_id, symbol)
                if not saved_factor.empty:
                    print(f"âœ… {symbol}: æŸ¥è¯¢åˆ° {len(saved_factor)} æ¡å› å­æ•°æ®")

            except Exception as e:
                print(f"âŒ {symbol}: å› å­åˆ†æå¤±è´¥ - {e}")

        return success_count > 0

    except Exception as e:
        print(f"âŒ å› å­åˆ†ææµ‹è¯•å¤±è´¥: {e}")
        return False


def test_time_series_features(stock_data):
    """æµ‹è¯•æ—¶é—´åºåˆ—ç‰¹å¾"""
    print("\n" + "=" * 50)
    print("ğŸ§ª æµ‹è¯• 5: æ—¶é—´åºåˆ—ç‰¹å¾")
    print("=" * 50)

    if not stock_data:
        print("âŒ æ— æ•°æ®å¯æµ‹è¯•")
        return False

    try:
        ts_extractor = TimeSeriesFeatures()
        feature_db = get_feature_database_manager()

        success_count = 0

        for symbol, data in stock_data.items():
            try:
                close_prices = data["close"]

                # æµ‹è¯•åŠ¨é‡ç‰¹å¾
                momentum_features = ts_extractor.extract_momentum_features(close_prices)
                print(
                    f"âœ… {symbol}: åŠ¨é‡ç‰¹å¾æå–æˆåŠŸï¼Œå…± {len(momentum_features)} ä¸ªç‰¹å¾"
                )

                # æµ‹è¯•æ³¢åŠ¨ç‡ç‰¹å¾
                volatility_features = ts_extractor.extract_volatility_features(
                    close_prices
                )
                print(
                    f"âœ… {symbol}: æ³¢åŠ¨ç‡ç‰¹å¾æå–æˆåŠŸï¼Œå…± {len(volatility_features)} ä¸ªç‰¹å¾"
                )

                # æµ‹è¯•è¶‹åŠ¿ç‰¹å¾
                trend_features = ts_extractor.extract_trend_features(close_prices)
                print(f"âœ… {symbol}: è¶‹åŠ¿ç‰¹å¾æå–æˆåŠŸï¼Œå…± {len(trend_features)} ä¸ªç‰¹å¾")

                # æµ‹è¯•æ‰€æœ‰ç‰¹å¾
                all_features = ts_extractor.extract_all_features(close_prices)
                print(
                    f"âœ… {symbol}: å…¨éƒ¨æ—¶é—´åºåˆ—ç‰¹å¾æå–æˆåŠŸï¼Œå…± {len(all_features)} ä¸ªç‰¹å¾"
                )

                # ä¿å­˜æ—¶é—´åºåˆ—ç‰¹å¾
                if feature_db.save_time_series_features(symbol, all_features):
                    print(f"âœ… {symbol}: æ—¶é—´åºåˆ—ç‰¹å¾å·²ä¿å­˜")
                    success_count += 1

                # æŸ¥è¯¢æ—¶é—´åºåˆ—ç‰¹å¾
                saved_features = feature_db.get_time_series_features(symbol)
                if not saved_features.empty:
                    print(f"âœ… {symbol}: æŸ¥è¯¢åˆ° {saved_features.shape} çš„æ—¶é—´åºåˆ—ç‰¹å¾")

            except Exception as e:
                print(f"âŒ {symbol}: æ—¶é—´åºåˆ—ç‰¹å¾æµ‹è¯•å¤±è´¥ - {e}")

        return success_count > 0

    except Exception as e:
        print(f"âŒ æ—¶é—´åºåˆ—ç‰¹å¾æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_graph_features(stock_data):
    """æµ‹è¯•å›¾ç‰¹å¾åˆ†æ"""
    print("\n" + "=" * 50)
    print("ğŸ§ª æµ‹è¯• 6: å›¾ç‰¹å¾åˆ†æ")
    print("=" * 50)

    if len(stock_data) < 2:
        print("âŒ éœ€è¦è‡³å°‘2åªè‚¡ç¥¨è¿›è¡Œå›¾ç‰¹å¾åˆ†æ")
        return False

    try:
        graph_analyzer = GraphAnalyzer()
        feature_db = get_feature_database_manager()

        # æ„å»ºæ”¶ç›Šç‡çŸ©é˜µ
        returns_matrix = pd.DataFrame()
        for symbol, data in stock_data.items():
            returns_matrix[symbol] = data["close"].pct_change()

        returns_matrix = returns_matrix.dropna()

        if returns_matrix.empty or len(returns_matrix) < 5:
            print("âš ï¸ æ”¶ç›Šç‡æ•°æ®ä¸è¶³ï¼Œè·³è¿‡å›¾ç‰¹å¾åˆ†æ")
            return False

        print(f"âœ… æ„å»ºæ”¶ç›Šç‡çŸ©é˜µ: {returns_matrix.shape}")

        # æå–å›¾ç‰¹å¾
        graph_features = graph_analyzer.extract_graph_features(returns_matrix)
        print(f"âœ… å›¾ç‰¹å¾æå–æˆåŠŸï¼Œå…± {len(graph_features)} ä¸ªç‰¹å¾")

        # æ˜¾ç¤ºéƒ¨åˆ†å›¾ç‰¹å¾ä¿¡æ¯
        for feature_name, feature_obj in list(graph_features.items())[:3]:
            print(f"   - {feature_name}: {feature_obj.description}")

        # ä¿å­˜å›¾ç‰¹å¾ (ä½¿ç”¨ç¬¬ä¸€å¤©çš„æ•°æ®ä½œä¸ºç¤ºä¾‹)
        test_date = returns_matrix.index[0]
        # å¤„ç†æ—¥æœŸæ—¶é—´è½¬æ¢
        if hasattr(test_date, "strftime"):
            test_date_str = test_date.strftime("%Y-%m-%d")
        else:
            test_date_str = str(test_date)[:10]

        success_count = 0

        for symbol in returns_matrix.columns:
            # æå–è¯¥è‚¡ç¥¨çš„å›¾ç‰¹å¾æ•°æ®
            symbol_features = {}
            feature_key = f"graph_centrality_{symbol}"

            if feature_key in graph_features:
                feature_obj = graph_features[feature_key]
                # è·å–ä¸­å¿ƒæ€§æŒ‡æ ‡
                symbol_features = feature_obj.values.copy()
                # æ·»åŠ ç‰¹å¾åå‰ç¼€
                symbol_features = {
                    f"{symbol}_{k}": v for k, v in symbol_features.items()
                }

            # è°ƒè¯•ä¿¡æ¯
            print(f"   - {symbol}: æå–åˆ° {len(symbol_features)} ä¸ªå›¾ç‰¹å¾")

            if symbol_features and feature_db.save_graph_features(
                symbol, test_date_str, symbol_features
            ):
                success_count += 1
            elif symbol_features:
                print(f"   - {symbol}: å›¾ç‰¹å¾ä¿å­˜å¤±è´¥")

        print(
            f"âœ… å›¾ç‰¹å¾å·²ä¿å­˜ï¼ŒæˆåŠŸ {success_count}/{len(returns_matrix.columns)} åªè‚¡ç¥¨"
        )

        return success_count > 0

    except Exception as e:
        print(f"âŒ å›¾ç‰¹å¾åˆ†ææµ‹è¯•å¤±è´¥: {e}")
        return False


def test_neural_factor_discovery(stock_data):
    """æµ‹è¯•ç¥ç»å› å­å‘ç° (ç®€åŒ–ç‰ˆæœ¬)"""
    print("\n" + "=" * 50)
    print("ğŸ§ª æµ‹è¯• 7: ç¥ç»å› å­å‘ç° (ç®€åŒ–ç‰ˆ)")
    print("=" * 50)

    try:
        # ç”±äºç¥ç»ç½‘ç»œè®­ç»ƒéœ€è¦å¤§é‡æ•°æ®å’Œè®¡ç®—èµ„æºï¼Œè¿™é‡Œåªæµ‹è¯•åŸºæœ¬åŠŸèƒ½
        from module_02_feature_engineering.factor_discovery.neural_factor_discovery import (
            DiscoveredFactor,
            FactorConfig,
            NeuralFactorDiscovery,
        )

        # åˆ›å»ºç®€åŒ–é…ç½®
        config = FactorConfig(
            input_dim=3,
            hidden_dims=[8, 4],
            output_dim=1,
            max_epochs=2,  # ä½¿ç”¨max_epochsè€Œä¸æ˜¯epochs
            learning_rate=0.01,
        )

        discoverer = NeuralFactorDiscovery(config)
        print("âœ… ç¥ç»å› å­å‘ç°å™¨åˆ›å»ºæˆåŠŸ")

        # æµ‹è¯•ä»Module01åŠ è½½æ•°æ®çš„åŠŸèƒ½
        symbols = list(stock_data.keys())
        try:
            # æ¨¡æ‹Ÿç‰¹å¾æ•°æ® (ç”±äºçœŸå®æ•°æ®åŠ è½½å¯èƒ½å¤±è´¥)
            mock_features = pd.DataFrame(
                {
                    "returns": np.random.randn(50) * 0.01,
                    "volatility": np.random.rand(50) * 0.05,
                    "volume_ratio": np.random.rand(50) * 2,
                }
            )
            mock_returns = mock_features["returns"].shift(-1).dropna()
            mock_features = mock_features.iloc[:-1]  # å¯¹é½æ•°æ®

            print(f"âœ… æ¨¡æ‹Ÿç‰¹å¾æ•°æ®å‡†å¤‡å®Œæˆ: {mock_features.shape}")

            # æµ‹è¯•ç¥ç»å› å­å‘ç° (çŸ­æ—¶é—´è®­ç»ƒ)
            discovered_factors = discoverer.discover_neural_factors(
                mock_features, mock_returns
            )
            print(f"âœ… ç¥ç»å› å­å‘ç°å®Œæˆï¼Œå‘ç° {len(discovered_factors)} ä¸ªå› å­")

            # æµ‹è¯•ä¿å­˜åŠŸèƒ½
            feature_db = get_feature_database_manager()
            if discovered_factors and discoverer.save_discovered_factors(
                discovered_factors
            ):
                print("âœ… ç¥ç»å› å­ä¿å­˜æˆåŠŸ")

                # æŸ¥è¯¢ç¥ç»å› å­
                saved_factors = feature_db.get_neural_factors()
                print(f"âœ… æŸ¥è¯¢åˆ° {len(saved_factors)} ä¸ªå·²ä¿å­˜çš„ç¥ç»å› å­")

            return True

        except ImportError:
            print("âš ï¸ PyTorchæœªå®‰è£…ï¼Œè·³è¿‡ç¥ç»å› å­å‘ç°æµ‹è¯•")
            return True
        except Exception as e:
            print(f"âš ï¸ ç¥ç»å› å­å‘ç°æµ‹è¯•éƒ¨åˆ†å¤±è´¥: {e}")
            return True  # ä¸å½±å“æ•´ä½“æµ‹è¯•

    except Exception as e:
        print(f"âŒ ç¥ç»å› å­å‘ç°æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_database_operations():
    """æµ‹è¯•æ•°æ®åº“æ“ä½œ"""
    print("\n" + "=" * 50)
    print("ğŸ§ª æµ‹è¯• 8: æ•°æ®åº“æ“ä½œ")
    print("=" * 50)

    try:
        feature_db = get_feature_database_manager()

        # è·å–æ•°æ®åº“ç»Ÿè®¡
        stats = feature_db.get_database_stats()
        print("âœ… æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯:")
        for key, value in stats.items():
            if key.endswith("_count"):
                print(f"   - {key}: {value:,}")
            elif key == "database_size_mb":
                print(f"   - {key}: {value:.2f} MB")
            else:
                print(f"   - {key}: {value}")

        # æµ‹è¯•æ•°æ®æ¸…ç†åŠŸèƒ½ (è°¨æ…ä½¿ç”¨)
        print("\nâš ï¸ æ•°æ®æ¸…ç†åŠŸèƒ½æµ‹è¯• (ä¸æ‰§è¡Œå®é™…æ¸…ç†)")
        # cleanup_result = feature_db.cleanup_old_data(days_to_keep=1000)  # ä¿ç•™1000å¤©çš„æ•°æ®
        # print(f"âœ… æ•°æ®æ¸…ç†å®Œæˆ: {cleanup_result}")

        return True

    except Exception as e:
        print(f"âŒ æ•°æ®åº“æ“ä½œæµ‹è¯•å¤±è´¥: {e}")
        return False


def test_cache_performance():
    """æµ‹è¯•ç¼“å­˜æ€§èƒ½"""
    print("\n" + "=" * 50)
    print("ğŸ§ª æµ‹è¯• 9: ç¼“å­˜æ€§èƒ½")
    print("=" * 50)

    try:
        cache = FeatureCacheManager(max_size=50, ttl=10)

        # æµ‹è¯•ç¼“å­˜å†™å…¥
        import time

        start_time = time.time()

        for i in range(100):
            test_data = {"indicator": f"test_{i}", "value": np.random.rand()}
            cache.set("performance_test", f"symbol_{i % 10}", test_data)

        write_time = time.time() - start_time
        print(f"âœ… ç¼“å­˜å†™å…¥æµ‹è¯•: 100æ¬¡å†™å…¥è€—æ—¶ {write_time * 1000:.2f}ms")

        # æµ‹è¯•ç¼“å­˜è¯»å–
        start_time = time.time()
        hit_count = 0

        for i in range(100):
            cached_data = cache.get("performance_test", f"symbol_{i % 10}")
            if cached_data is not None:
                hit_count += 1

        read_time = time.time() - start_time
        print(
            f"âœ… ç¼“å­˜è¯»å–æµ‹è¯•: 100æ¬¡è¯»å–è€—æ—¶ {read_time * 1000:.2f}ms, å‘½ä¸­ç‡ {hit_count}%"
        )

        # è·å–ç¼“å­˜ç»Ÿè®¡
        cache_stats = cache.get_stats()
        print(f"âœ… ç¼“å­˜ç»Ÿè®¡: {cache_stats}")

        return True

    except Exception as e:
        print(f"âŒ ç¼“å­˜æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("ğŸš€ å¼€å§‹ Module 02 ç‰¹å¾å·¥ç¨‹æ¨¡å—æµ‹è¯•")
    print(f"â° æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    test_results = []

    # æ‰§è¡Œæ‰€æœ‰æµ‹è¯•
    test_results.append(("åŸºæœ¬ç¯å¢ƒè®¾ç½®", test_basic_setup()))

    stock_data = test_data_loading()
    test_results.append(("æ•°æ®åŠ è½½", len(stock_data) > 0))

    test_results.append(("æŠ€æœ¯æŒ‡æ ‡è®¡ç®—", test_technical_indicators(stock_data)))
    test_results.append(("å› å­åˆ†æ", test_factor_analysis(stock_data)))
    test_results.append(("æ—¶é—´åºåˆ—ç‰¹å¾", test_time_series_features(stock_data)))
    test_results.append(("å›¾ç‰¹å¾åˆ†æ", test_graph_features(stock_data)))
    test_results.append(("ç¥ç»å› å­å‘ç°", test_neural_factor_discovery(stock_data)))
    test_results.append(("æ•°æ®åº“æ“ä½œ", test_database_operations()))
    test_results.append(("ç¼“å­˜æ€§èƒ½", test_cache_performance()))

    # æ±‡æ€»æµ‹è¯•ç»“æœ
    print("\n" + "=" * 60)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»")
    print("=" * 60)

    passed = 0
    total = len(test_results)

    for test_name, result in test_results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{test_name:20} : {status}")
        if result:
            passed += 1

    print(f"\nğŸ¯ æ€»ä½“ç»“æœ: {passed}/{total} æµ‹è¯•é€šè¿‡")

    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡! Module 02 ç‰¹å¾å·¥ç¨‹æ¨¡å—è¿è¡Œæ­£å¸¸")
    elif passed >= total * 0.8:
        print("âš ï¸ å¤§éƒ¨åˆ†æµ‹è¯•é€šè¿‡ï¼Œæ¨¡å—åŸºæœ¬å¯ç”¨")
    else:
        print("ğŸ’¥ å¤šé¡¹æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥æ¨¡å—é…ç½®")

    # æœ€ç»ˆçŠ¶æ€æ£€æŸ¥
    try:
        feature_db = get_feature_database_manager()
        final_stats = feature_db.get_database_stats()
        print(f"\nğŸ“ˆ æµ‹è¯•åæ•°æ®åº“çŠ¶æ€: {final_stats.get('database_size_mb', 0):.2f} MB")
        print(f"ğŸ’¾ æŠ€æœ¯æŒ‡æ ‡è®°å½•: {final_stats.get('technical_indicators_count', 0):,}")
        print(f"ğŸ” å› å­æ•°æ®è®°å½•: {final_stats.get('factor_data_count', 0):,}")
        print(f"ğŸ§  ç¥ç»å› å­æ•°é‡: {final_stats.get('neural_factors_count', 0):,}")
    except Exception as e:
        print(f"âš ï¸ æ— æ³•è·å–æœ€ç»ˆçŠ¶æ€: {e}")

    return passed >= total * 0.8


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
