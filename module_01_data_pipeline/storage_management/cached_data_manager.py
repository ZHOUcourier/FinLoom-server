"""
ç¼“å­˜æ•°æ®ç®¡ç†å™¨
ä¼˜å…ˆä»æœ¬åœ°æ•°æ®åº“è¯»å–æ•°æ®ï¼Œåªåœ¨å¿…è¦æ—¶æ‰ä»AKshareè·å–
"""

from datetime import datetime, timedelta
from typing import Dict, List, Optional
import pandas as pd

from common.logging_system import setup_logger
from module_01_data_pipeline.data_acquisition.akshare_collector import AkshareDataCollector
from module_01_data_pipeline.storage_management.database_manager import DatabaseManager

logger = setup_logger("cached_data_manager")


class CachedDataManager:
    """ç¼“å­˜æ•°æ®ç®¡ç†å™¨ - ä¼˜å…ˆä½¿ç”¨æœ¬åœ°æ•°æ®"""
    
    def __init__(self, db_path: str = "data/finloom.db", update_threshold_days: int = 1):
        """
        åˆå§‹åŒ–ç¼“å­˜æ•°æ®ç®¡ç†å™¨
        
        Args:
            db_path: æ•°æ®åº“è·¯å¾„
            update_threshold_days: æ•°æ®æ›´æ–°é˜ˆå€¼ï¼ˆå¤©ï¼‰
        """
        self.db_manager = DatabaseManager(db_path)
        self.collector = AkshareDataCollector(rate_limit=0.3)
        self.update_threshold_days = update_threshold_days
        
        logger.info("âœ… ç¼“å­˜æ•°æ®ç®¡ç†å™¨å·²å¯åŠ¨ - ä¼˜å…ˆä½¿ç”¨æœ¬åœ°æ•°æ®")
    
    def get_stock_history(
        self,
        symbol: str,
        start_date: str,
        end_date: str,
        force_update: bool = False
    ) -> pd.DataFrame:
        """
        è·å–è‚¡ç¥¨å†å²æ•°æ®ï¼ˆä¼˜å…ˆä»æœ¬åœ°è¯»å–ï¼‰
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD æˆ– YYYYMMDD)
            end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD æˆ– YYYYMMDD)
            force_update: æ˜¯å¦å¼ºåˆ¶ä»ç½‘ç»œæ›´æ–°
            
        Returns:
            å†å²æ•°æ®DataFrame
        """
        try:
            # æ ‡å‡†åŒ–æ—¥æœŸæ ¼å¼
            start_date_std = self._standardize_date(start_date)
            end_date_std = self._standardize_date(end_date)
            
            if not force_update:
                # 1. å…ˆå°è¯•ä»æœ¬åœ°æ•°æ®åº“è¯»å–
                local_data = self.db_manager.get_stock_prices(
                    symbol=symbol,
                    start_date=start_date_std,
                    end_date=end_date_std
                )
                
                if not local_data.empty:
                    # æ£€æŸ¥æ•°æ®æ˜¯å¦éœ€è¦æ›´æ–°
                    need_update = self._check_need_update(local_data, end_date_std)
                    
                    if not need_update:
                        logger.info(f"âœ… ä»æœ¬åœ°æ•°æ®åº“è¯»å– {symbol} æ•°æ® ({len(local_data)} æ¡)")
                        return local_data
                    else:
                        logger.info(f"âš ï¸ æœ¬åœ°æ•°æ®éœ€è¦æ›´æ–°ï¼Œä»ç½‘ç»œè·å–æœ€æ–°æ•°æ®...")
            
            # 2. ä»ç½‘ç»œè·å–æ•°æ®
            logger.info(f"ğŸŒ ä»AKshareè·å– {symbol} æ•°æ®...")
            
            # è½¬æ¢ä¸ºAKshareæ ¼å¼ (YYYYMMDD)
            start_date_ak = start_date_std.replace("-", "")
            end_date_ak = end_date_std.replace("-", "")
            
            df = self.collector.fetch_stock_history(
                symbol=symbol,
                start_date=start_date_ak,
                end_date=end_date_ak,
                period="daily",
                adjust="qfq"
            )
            
            if not df.empty:
                # æ ‡å‡†åŒ–åˆ—å
                df = self._standardize_columns(df)
                
                # ä¿å­˜åˆ°æœ¬åœ°æ•°æ®åº“
                self.db_manager.save_stock_prices(symbol, df)
                logger.info(f"âœ… å·²æ›´æ–°æœ¬åœ°æ•°æ®åº“ {symbol} ({len(df)} æ¡)")
                
                return df
            else:
                logger.warning(f"âš ï¸ æœªè·å–åˆ° {symbol} çš„æ•°æ®")
                return pd.DataFrame()
                
        except Exception as e:
            logger.error(f"è·å– {symbol} å†å²æ•°æ®å¤±è´¥: {e}")
            
            # å¦‚æœç½‘ç»œè·å–å¤±è´¥ï¼Œå°è¯•è¿”å›æœ¬åœ°æ•°æ®ï¼ˆå³ä½¿å¯èƒ½è¿‡æœŸï¼‰
            try:
                local_data = self.db_manager.get_stock_prices(
                    symbol=symbol,
                    start_date=start_date_std,
                    end_date=end_date_std
                )
                if not local_data.empty:
                    logger.warning(f"âš ï¸ è¿”å›æœ¬åœ°ç¼“å­˜æ•°æ® {symbol} (å¯èƒ½ä¸æ˜¯æœ€æ–°)")
                    return local_data
            except:
                pass
            
            return pd.DataFrame()
    
    def get_stock_list(self, force_update: bool = False) -> pd.DataFrame:
        """
        è·å–è‚¡ç¥¨åˆ—è¡¨ï¼ˆä¼˜å…ˆä»æœ¬åœ°è¯»å–ï¼‰
        
        Args:
            force_update: æ˜¯å¦å¼ºåˆ¶ä»ç½‘ç»œæ›´æ–°
            
        Returns:
            è‚¡ç¥¨åˆ—è¡¨DataFrame
        """
        try:
            if not force_update:
                # TODO: ä»æ•°æ®åº“è¯»å–è‚¡ç¥¨åˆ—è¡¨
                # ç›®å‰ç›´æ¥ä»ç½‘ç»œè·å–
                pass
            
            # ä»AKshareè·å–
            logger.info("ğŸŒ ä»AKshareè·å–è‚¡ç¥¨åˆ—è¡¨...")
            stock_list = self.collector.fetch_stock_list("Aè‚¡")
            
            if not stock_list.empty:
                logger.info(f"âœ… è·å–åˆ° {len(stock_list)} åªè‚¡ç¥¨")
                
                # ä¿å­˜åˆ°æ•°æ®åº“
                for _, row in stock_list.iterrows():
                    try:
                        symbol = row.get('ä»£ç ', row.get('symbol', ''))
                        name = row.get('åç§°', row.get('name', ''))
                        
                        if symbol and name:
                            self.db_manager.save_stock_info(
                                symbol=str(symbol),
                                name=str(name),
                                sector=row.get('è¡Œä¸š', None)
                            )
                    except:
                        continue
            
            return stock_list
            
        except Exception as e:
            logger.error(f"è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def get_macro_data(
        self,
        indicator_type: str,
        force_update: bool = False
    ) -> pd.DataFrame:
        """
        è·å–å®è§‚æ•°æ®ï¼ˆä¼˜å…ˆä»æœ¬åœ°è¯»å–ï¼‰
        
        Args:
            indicator_type: æŒ‡æ ‡ç±»å‹ (GDP, CPI, PMIç­‰)
            force_update: æ˜¯å¦å¼ºåˆ¶ä»ç½‘ç»œæ›´æ–°
            
        Returns:
            å®è§‚æ•°æ®DataFrame
        """
        try:
            if not force_update:
                # ä»æœ¬åœ°æ•°æ®åº“è¯»å–
                local_data = self.db_manager.get_macro_data(indicator_type=indicator_type)
                
                if not local_data.empty:
                    # æ£€æŸ¥æ•°æ®æ˜¯å¦éœ€è¦æ›´æ–°ï¼ˆå®è§‚æ•°æ®æ›´æ–°é¢‘ç‡è¾ƒä½ï¼‰
                    last_date = local_data['date'].max()
                    days_old = (datetime.now() - pd.to_datetime(last_date)).days
                    
                    if days_old < 30:  # 30å¤©å†…çš„æ•°æ®è®¤ä¸ºæ˜¯æ–°çš„
                        logger.info(f"âœ… ä»æœ¬åœ°æ•°æ®åº“è¯»å– {indicator_type} æ•°æ® ({len(local_data)} æ¡)")
                        return local_data
            
            # ä»ç½‘ç»œè·å–
            logger.info(f"ğŸŒ ä»AKshareè·å– {indicator_type} æ•°æ®...")
            from module_01_data_pipeline.data_acquisition.alternative_data_collector import ChineseAlternativeDataCollector
            
            alt_collector = ChineseAlternativeDataCollector(rate_limit=0.5)
            macro_data = alt_collector.fetch_macro_economic_data(indicator_type)
            
            if macro_data and indicator_type in macro_data:
                df = macro_data[indicator_type]
                if not df.empty:
                    # ä¿å­˜åˆ°æ•°æ®åº“
                    self.db_manager.save_macro_data(indicator_type, df)
                    logger.info(f"âœ… å·²æ›´æ–°æœ¬åœ°æ•°æ®åº“ {indicator_type} ({len(df)} æ¡)")
                    return df
            
            return pd.DataFrame()
            
        except Exception as e:
            logger.error(f"è·å– {indicator_type} å®è§‚æ•°æ®å¤±è´¥: {e}")
            
            # è¿”å›æœ¬åœ°æ•°æ®ï¼ˆå³ä½¿å¯èƒ½è¿‡æœŸï¼‰
            try:
                local_data = self.db_manager.get_macro_data(indicator_type=indicator_type)
                if not local_data.empty:
                    logger.warning(f"âš ï¸ è¿”å›æœ¬åœ°ç¼“å­˜æ•°æ® {indicator_type}")
                    return local_data
            except:
                pass
            
            return pd.DataFrame()
    
    def get_sector_data(
        self,
        date: Optional[str] = None,
        force_update: bool = False
    ) -> pd.DataFrame:
        """
        è·å–æ¿å—æ•°æ®ï¼ˆä¼˜å…ˆä»æœ¬åœ°è¯»å–ï¼‰
        
        Args:
            date: æ—¥æœŸ (YYYY-MM-DD)ï¼ŒNoneè¡¨ç¤ºæœ€æ–°
            force_update: æ˜¯å¦å¼ºåˆ¶ä»ç½‘ç»œæ›´æ–°
            
        Returns:
            æ¿å—æ•°æ®DataFrame
        """
        try:
            if date is None:
                date = datetime.now().strftime("%Y-%m-%d")
            
            if not force_update:
                # ä»æœ¬åœ°æ•°æ®åº“è¯»å–
                local_data = self.db_manager.get_sector_data(date=date)
                
                if not local_data.empty:
                    logger.info(f"âœ… ä»æœ¬åœ°æ•°æ®åº“è¯»å–æ¿å—æ•°æ® ({len(local_data)} ä¸ªæ¿å—)")
                    return local_data
            
            # ä»ç½‘ç»œè·å–
            logger.info("ğŸŒ ä»AKshareè·å–æ¿å—æ•°æ®...")
            from module_01_data_pipeline.data_acquisition.alternative_data_collector import ChineseAlternativeDataCollector
            
            alt_collector = ChineseAlternativeDataCollector(rate_limit=0.5)
            sector_df = alt_collector.fetch_sector_performance()
            
            if not sector_df.empty:
                # ä¿å­˜åˆ°æ•°æ®åº“
                self.db_manager.save_sector_data(sector_df, date=date)
                logger.info(f"âœ… å·²æ›´æ–°æœ¬åœ°æ•°æ®åº“æ¿å—æ•°æ® ({len(sector_df)} ä¸ªæ¿å—)")
                return sector_df
            
            return pd.DataFrame()
            
        except Exception as e:
            logger.error(f"è·å–æ¿å—æ•°æ®å¤±è´¥: {e}")
            
            # è¿”å›æœ¬åœ°æ•°æ®
            try:
                local_data = self.db_manager.get_sector_data(date=date)
                if not local_data.empty:
                    logger.warning(f"âš ï¸ è¿”å›æœ¬åœ°ç¼“å­˜æ¿å—æ•°æ®")
                    return local_data
            except:
                pass
            
            return pd.DataFrame()
    
    def update_latest_data(self, symbols: List[str] = None):
        """
        æ›´æ–°æœ€æ–°æ•°æ®ï¼ˆæ¯æ—¥å¢é‡æ›´æ–°ï¼‰
        
        Args:
            symbols: è¦æ›´æ–°çš„è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼ŒNoneè¡¨ç¤ºæ›´æ–°æ‰€æœ‰
        """
        logger.info("å¼€å§‹æ›´æ–°æœ€æ–°æ•°æ®...")
        
        try:
            # å¦‚æœæ²¡æœ‰æŒ‡å®šè‚¡ç¥¨ï¼Œä»æ•°æ®åº“è·å–æ‰€æœ‰è‚¡ç¥¨
            if symbols is None:
                symbols = self.db_manager.get_symbols_list()
                if not symbols:
                    logger.warning("æ•°æ®åº“ä¸­æ²¡æœ‰è‚¡ç¥¨æ•°æ®ï¼Œè¯·å…ˆè¿è¡Œåˆå§‹åŒ–è„šæœ¬")
                    return
            
            today = datetime.now().strftime("%Y%m%d")
            yesterday = (datetime.now() - timedelta(days=1)).strftime("%Y%m%d")
            
            updated_count = 0
            for symbol in symbols:
                try:
                    # è·å–æœ€è¿‘2å¤©çš„æ•°æ®ï¼ˆç¡®ä¿è·å–åˆ°æœ€æ–°ï¼‰
                    df = self.collector.fetch_stock_history(
                        symbol=symbol,
                        start_date=yesterday,
                        end_date=today,
                        period="daily",
                        adjust="qfq"
                    )
                    
                    if not df.empty:
                        df = self._standardize_columns(df)
                        self.db_manager.save_stock_prices(symbol, df)
                        updated_count += 1
                        
                        if updated_count % 10 == 0:
                            logger.info(f"å·²æ›´æ–° {updated_count}/{len(symbols)} åªè‚¡ç¥¨")
                    
                except Exception as e:
                    logger.error(f"æ›´æ–° {symbol} å¤±è´¥: {e}")
                    continue
            
            logger.info(f"âœ… å®Œæˆæ›´æ–°ï¼Œå…±æ›´æ–° {updated_count} åªè‚¡ç¥¨")
            
        except Exception as e:
            logger.error(f"æ›´æ–°æœ€æ–°æ•°æ®å¤±è´¥: {e}")
    
    def _check_need_update(self, df: pd.DataFrame, end_date: str) -> bool:
        """
        æ£€æŸ¥æ•°æ®æ˜¯å¦éœ€è¦æ›´æ–°
        
        Args:
            df: æœ¬åœ°æ•°æ®
            end_date: è¯·æ±‚çš„ç»“æŸæ—¥æœŸ
            
        Returns:
            æ˜¯å¦éœ€è¦æ›´æ–°
        """
        if df.empty:
            return True
        
        # è·å–æœ¬åœ°æ•°æ®çš„æœ€åæ—¥æœŸ
        last_date = df.index.max()
        
        # è½¬æ¢ä¸ºdatetime
        if isinstance(last_date, str):
            last_date = pd.to_datetime(last_date)
        
        end_date_dt = pd.to_datetime(end_date)
        
        # è®¡ç®—å¤©æ•°å·®
        days_diff = (end_date_dt - last_date).days
        
        # å¦‚æœæ•°æ®è¶…è¿‡é˜ˆå€¼å¤©æ•°ï¼Œéœ€è¦æ›´æ–°
        return days_diff > self.update_threshold_days
    
    def _standardize_date(self, date_str: str) -> str:
        """
        æ ‡å‡†åŒ–æ—¥æœŸæ ¼å¼ä¸º YYYY-MM-DD
        
        Args:
            date_str: æ—¥æœŸå­—ç¬¦ä¸² (YYYY-MM-DD æˆ– YYYYMMDD)
            
        Returns:
            æ ‡å‡†åŒ–çš„æ—¥æœŸå­—ç¬¦ä¸² (YYYY-MM-DD)
        """
        # å»é™¤å¯èƒ½çš„è¿å­—ç¬¦
        date_str = date_str.replace("-", "")
        
        # è½¬æ¢ä¸º YYYY-MM-DD æ ¼å¼
        if len(date_str) == 8:
            return f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:8]}"
        
        return date_str
    
    def _standardize_columns(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ ‡å‡†åŒ–DataFrameåˆ—å"""
        column_mapping = {
            'æ—¥æœŸ': 'date',
            'å¼€ç›˜': 'open',
            'æ”¶ç›˜': 'close',
            'æœ€é«˜': 'high',
            'æœ€ä½': 'low',
            'æˆäº¤é‡': 'volume',
            'æˆäº¤é¢': 'amount',
            'æ¶¨è·Œå¹…': 'pct_change',
            'æ¶¨è·Œé¢': 'change',
            'æ¢æ‰‹ç‡': 'turnover_rate',
        }
        
        df = df.copy()
        df.rename(columns=column_mapping, inplace=True)
        
        return df
    
    def get_statistics(self) -> Dict:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        return self.db_manager.get_database_stats()


# å…¨å±€å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰
_global_cached_manager = None


def get_cached_data_manager(db_path: str = "data/finloom.db") -> CachedDataManager:
    """
    è·å–å…¨å±€ç¼“å­˜æ•°æ®ç®¡ç†å™¨å®ä¾‹
    
    Args:
        db_path: æ•°æ®åº“è·¯å¾„
        
    Returns:
        ç¼“å­˜æ•°æ®ç®¡ç†å™¨å®ä¾‹
    """
    global _global_cached_manager
    if _global_cached_manager is None:
        _global_cached_manager = CachedDataManager(db_path)
    return _global_cached_manager






