#!/usr/bin/env python3
"""
æ•°æ®ç®¡é“åè°ƒå™¨ - ç»Ÿä¸€ç®¡ç†æ™ºèƒ½åˆ†æé¡µé¢æ‰€éœ€çš„æ‰€æœ‰æ•°æ®
è´Ÿè´£åè°ƒæ¿å—åˆ†æã€å¸‚åœºæƒ…ç»ªã€æŠ€æœ¯æŒ‡æ ‡ã€å¸‚åœºèµ„è®¯ç­‰æ•°æ®çš„è·å–å’Œæ›´æ–°
"""

import asyncio
from datetime import datetime, timedelta
from typing import Dict, List, Optional

import pandas as pd

from common.logging_system import setup_logger

logger = setup_logger("data_pipeline_coordinator")


class DataPipelineCoordinator:
    """æ•°æ®ç®¡é“åè°ƒå™¨ - åè°ƒæ‰€æœ‰æ•°æ®æº"""

    def __init__(self):
        """åˆå§‹åŒ–æ•°æ®ç®¡é“åè°ƒå™¨"""
        self.initialized = False
        self.db_manager = None
        self.cached_manager = None
        self.akshare_collector = None
        self.alternative_collector = None
        self.tonghuashun_collector = None  # æ–°å¢åŒèŠ±é¡ºé‡‡é›†å™¨

    def initialize(self):
        """å»¶è¿Ÿåˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶"""
        if self.initialized:
            return True

        try:
            logger.info("ğŸ”§ åˆå§‹åŒ–æ•°æ®ç®¡é“åè°ƒå™¨...")

            # å¯¼å…¥æ•°æ®ç®¡ç†å™¨
            from module_01_data_pipeline import get_database_manager
            from module_01_data_pipeline.storage_management.cached_data_manager import (
                CachedDataManager,
            )

            self.db_manager = get_database_manager()
            self.cached_manager = CachedDataManager()

            # å¯¼å…¥æ•°æ®é‡‡é›†å™¨
            from module_01_data_pipeline.data_acquisition.akshare_collector import (
                AkshareDataCollector,
            )
            from module_01_data_pipeline.data_acquisition.alternative_data_collector import (
                ChineseAlternativeDataCollector,
            )
            from module_01_data_pipeline.data_acquisition.tonghuashun_collector import (
                get_tonghuashun_collector,
            )

            self.akshare_collector = AkshareDataCollector(rate_limit=0.5)
            self.alternative_collector = ChineseAlternativeDataCollector(rate_limit=0.5)
            # åŒèŠ±é¡ºé‡‡é›†å™¨ï¼ˆé»˜è®¤ä¸ä½¿ç”¨ä»£ç†ï¼Œå¯é…ç½®ï¼‰
            self.tonghuashun_collector = get_tonghuashun_collector(use_proxy=False)

            self.initialized = True
            logger.info("âœ… æ•°æ®ç®¡é“åè°ƒå™¨åˆå§‹åŒ–æˆåŠŸï¼ˆå«åŒèŠ±é¡ºæ•°æ®æºï¼‰")
            return True

        except Exception as e:
            logger.error(f"âŒ æ•°æ®ç®¡é“åè°ƒå™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            return False

    async def fetch_sector_analysis_data(self) -> Dict:
        """è·å–æ¿å—åˆ†ææ•°æ®"""
        try:
            logger.info("ğŸ“Š è·å–æ¿å—åˆ†ææ•°æ®...")

            if not self.initialized:
                self.initialize()

            today = datetime.now().strftime("%Y-%m-%d")

            # ä¼˜å…ˆä»ç¼“å­˜è·å–
            sector_df = self.cached_manager.get_sector_data(date=today)

            # å¦‚æœç¼“å­˜ä¸ºç©ºï¼Œå¼ºåˆ¶ä»ç½‘ç»œæ›´æ–°
            if sector_df.empty:
                logger.info("âš ï¸ ç¼“å­˜æ— æ•°æ®ï¼Œä»ç½‘ç»œè·å–...")
                sector_df = self.cached_manager.get_sector_data(
                    date=today, force_update=True
                )

            if sector_df.empty:
                logger.warning("âš ï¸ æ¿å—æ•°æ®ä¸ºç©º")
                return {"success": False, "data": [], "message": "æ— æ¿å—æ•°æ®"}

            # å¤„ç†æ•°æ®
            sectors = self._process_sector_data(sector_df)

            logger.info(f"âœ… è·å–æ¿å—åˆ†ææ•°æ®æˆåŠŸ: {len(sectors)} ä¸ªæ¿å—")
            return {"success": True, "data": sectors, "count": len(sectors)}

        except Exception as e:
            logger.error(f"âŒ è·å–æ¿å—åˆ†ææ•°æ®å¤±è´¥: {e}")
            import traceback

            traceback.print_exc()
            return {"success": False, "data": [], "message": str(e)}

    def _process_sector_data(self, sector_df: pd.DataFrame) -> List[Dict]:
        """å¤„ç†æ¿å—æ•°æ®"""
        sectors = []

        # æ¿å—æ˜ å°„
        sector_mapping = {
            "ç§‘æŠ€": {"icon": "mdi-laptop", "color": "primary"},
            "åŒ»è¯": {"icon": "mdi-medical-bag", "color": "success"},
            "é‡‘è": {"icon": "mdi-bank", "color": "info"},
            "æ¶ˆè´¹": {"icon": "mdi-shopping", "color": "warning"},
            "èƒ½æº": {"icon": "mdi-lightning-bolt", "color": "error"},
            "å·¥ä¸š": {"icon": "mdi-factory", "color": "secondary"},
            "ææ–™": {"icon": "mdi-cube-outline", "color": "brown"},
            "æˆ¿åœ°äº§": {"icon": "mdi-home", "color": "deep-orange"},
            "é€šä¿¡": {"icon": "mdi-cellphone", "color": "cyan"},
            "å…¬ç”¨äº‹ä¸š": {"icon": "mdi-water", "color": "light-blue"},
        }

        for _, row in sector_df.head(10).iterrows():
            try:
                sector_name = str(row.get("æ¿å—åç§°", row.get("sector_name", "æœªçŸ¥")))

                # è·å–æ¶¨è·Œå¹…
                change_pct = 0.0
                for col in ["æ¶¨è·Œå¹…", "change_pct", "æ¶¨è·Œå¹…%"]:
                    if col in row:
                        try:
                            val = row[col]
                            if isinstance(val, str):
                                val = val.replace("%", "")
                            change_pct = float(val)
                            break
                        except:
                            continue

                # è·å–è‚¡ç¥¨æ•°é‡
                count = 0
                for col in ["æˆåˆ†è‚¡æ•°é‡", "count", "å…¬å¸æ•°é‡"]:
                    if col in row:
                        try:
                            count = int(row[col])
                            break
                        except:
                            continue

                # åŒ¹é…æ¿å—é…ç½®
                sector_config = {"icon": "mdi-chart-pie", "color": "primary"}
                for key, config in sector_mapping.items():
                    if key in sector_name:
                        sector_config = config
                        break

                sectors.append(
                    {
                        "name": sector_name,
                        "change": (
                            change_pct / 100 if change_pct > 1 else change_pct
                        ),  # è½¬æ¢ä¸ºå°æ•°
                        "count": count,
                        "icon": sector_config["icon"],
                        "color": sector_config["color"],
                    }
                )
            except Exception as e:
                logger.warning(f"å¤„ç†æ¿å—æ•°æ®å¤±è´¥: {e}")
                continue

        return sectors

    async def fetch_market_sentiment_data(self) -> Dict:
        """
        è·å–å¸‚åœºæƒ…ç»ªæ•°æ®ï¼ˆæ”¹è¿›ç‰ˆï¼‰
        ä½¿ç”¨åŠ æƒç®—æ³•ï¼Œè€ƒè™‘ä¸ªè‚¡æ¶¨è·Œå¹…å’Œå¸‚å€¼/æˆäº¤é‡æƒé‡
        """
        try:
            logger.info("ğŸ’­ è·å–å¸‚åœºæƒ…ç»ªæ•°æ®...")

            if not self.initialized:
                self.initialize()

            # å¯¼å…¥æ”¹è¿›çš„æƒ…ç»ªè®¡ç®—å™¨
            from module_01_data_pipeline.data_processing.market_sentiment_calculator import (
                MarketSentimentCalculator
            )
            
            calculator = MarketSentimentCalculator()
            today = datetime.now().strftime("%Y-%m-%d")

            # è·å–è‚¡ç¥¨æ•°æ®ç”¨äºè®¡ç®—
            stock_data_list = []
            
            try:
                # è·å–è‚¡ç¥¨åˆ—è¡¨
                stock_list = self.db_manager.get_stock_list()
                
                if not stock_list.empty:
                    logger.info(f"ğŸ“Š è·å–åˆ° {len(stock_list)} åªè‚¡ç¥¨ï¼Œå¼€å§‹è®¡ç®—æƒ…ç»ªæŒ‡æ•°...")
                    
                    # æ”¶é›†è‚¡ç¥¨æ•°æ®ï¼ˆé™åˆ¶æ•°é‡ä»¥æé«˜é€Ÿåº¦ï¼‰
                    for _, stock_row in stock_list.head(300).iterrows():
                        symbol = stock_row.get('symbol', '')
                        if not symbol:
                            continue
                        
                        try:
                            # è·å–è¯¥è‚¡ç¥¨ä»Šæ—¥æ•°æ®
                            price_data = self.db_manager.get_stock_prices(
                                symbol=symbol,
                                start_date=today,
                                end_date=today
                            )
                            
                            if not price_data.empty and 'pct_change' in price_data.columns:
                                stock_info = {
                                    'symbol': symbol,
                                    'change_pct': float(price_data['pct_change'].iloc[-1]),
                                    'volume': float(price_data.get('volume', pd.Series([0])).iloc[-1]) if 'volume' in price_data.columns else 1.0,
                                    'market_cap': 1.0  # å¸‚å€¼æ•°æ®æš‚æ—¶ä½¿ç”¨é»˜è®¤å€¼
                                }
                                stock_data_list.append(stock_info)
                        except:
                            continue
                    
                    logger.info(f"ğŸ“ˆ æˆåŠŸæ”¶é›† {len(stock_data_list)} åªè‚¡ç¥¨æ•°æ®")

            except Exception as e:
                logger.warning(f"è·å–è‚¡ç¥¨æ•°æ®å¤±è´¥: {e}")

            # ä½¿ç”¨æ”¹è¿›çš„ç®—æ³•è®¡ç®—å¸‚åœºæƒ…ç»ª
            if stock_data_list:
                stock_df = pd.DataFrame(stock_data_list)
                sentiment_result = calculator.calculate_sentiment(
                    stock_df,
                    weight_method='volume'  # ä½¿ç”¨æˆäº¤é‡åŠ æƒ
                )
                
                result = {
                    "success": True,
                    "data": {
                        "fear_greed_index": sentiment_result['fear_greed_index'],
                        "sentiment_level": sentiment_result['sentiment_level'],
                        "sentiment_description": sentiment_result['sentiment_description'],
                        "advancing_stocks": sentiment_result['advancing_stocks'],
                        "declining_stocks": sentiment_result['declining_stocks'],
                        "unchanged_stocks": sentiment_result.get('unchanged_stocks', 0),
                        "total_stocks": sentiment_result['total_stocks'],
                        "breadth_index": sentiment_result.get('breadth_index', 50),
                        "distribution": sentiment_result.get('distribution', {}),
                    },
                }
                
                logger.info(
                    f"âœ… å¸‚åœºæƒ…ç»ªè®¡ç®—å®Œæˆ: {sentiment_result['sentiment_level']} "
                    f"(æŒ‡æ•°={sentiment_result['fear_greed_index']:.2f})"
                )
            else:
                # ä½¿ç”¨é»˜è®¤å€¼
                logger.warning("âš ï¸ æ— å¯ç”¨è‚¡ç¥¨æ•°æ®ï¼Œè¿”å›é»˜è®¤æƒ…ç»ªæŒ‡æ ‡")
                result = {
                    "success": True,
                    "data": {
                        "fear_greed_index": 50,
                        "sentiment_level": "ä¸­æ€§",
                        "sentiment_description": "æš‚æ— æ•°æ®",
                        "advancing_stocks": 2500,
                        "declining_stocks": 2000,
                        "unchanged_stocks": 0,
                        "total_stocks": 4500,
                        "breadth_index": 50,
                        "distribution": {},
                    },
                }

            return result

        except Exception as e:
            logger.error(f"âŒ è·å–å¸‚åœºæƒ…ç»ªæ•°æ®å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            
            return {
                "success": False,
                "data": {
                    "fear_greed_index": 50,
                    "sentiment_level": "ä¸­æ€§",
                    "sentiment_description": "æ•°æ®è·å–å¤±è´¥",
                    "advancing_stocks": 0,
                    "declining_stocks": 0,
                    "unchanged_stocks": 0,
                    "total_stocks": 0,
                    "breadth_index": 50,
                    "distribution": {},
                },
                "message": str(e),
            }

    async def fetch_technical_indicators_data(self) -> Dict:
        """è·å–æŠ€æœ¯æŒ‡æ ‡æ•°æ®"""
        try:
            logger.info("ğŸ“ˆ è·å–æŠ€æœ¯æŒ‡æ ‡æ•°æ®...")

            if not self.initialized:
                self.initialize()

            # è·å–ä¸Šè¯æŒ‡æ•°æ•°æ®
            end_date = datetime.now()
            start_date = end_date - timedelta(days=60)  # è·å–60å¤©æ•°æ®ç¡®ä¿å¤Ÿç”¨

            index_data = self.db_manager.get_stock_prices(
                symbol="sh000001",
                start_date=start_date.strftime("%Y-%m-%d"),
                end_date=end_date.strftime("%Y-%m-%d"),
            )

            if index_data.empty or len(index_data) < 30:
                logger.warning("âš ï¸ ä¸Šè¯æŒ‡æ•°æ•°æ®ä¸è¶³ï¼Œå°è¯•è®¡ç®—ä¼°ç®—æŒ‡æ ‡")
                # è¿”å›ä¼°ç®—æŒ‡æ ‡
                indicators = self._get_estimated_indicators()
            else:
                # è®¡ç®—çœŸå®æŠ€æœ¯æŒ‡æ ‡
                indicators = self._calculate_technical_indicators(index_data)

            logger.info(f"âœ… æŠ€æœ¯æŒ‡æ ‡æ•°æ®è·å–æˆåŠŸ: {len(indicators)} ä¸ªæŒ‡æ ‡")
            return {
                "success": True,
                "data": indicators,
                "count": len(indicators),
                "based_on": "ä¸Šè¯æŒ‡æ•°",
            }

        except Exception as e:
            logger.error(f"âŒ è·å–æŠ€æœ¯æŒ‡æ ‡æ•°æ®å¤±è´¥: {e}")
            import traceback

            traceback.print_exc()
            return {
                "success": False,
                "data": self._get_estimated_indicators(),
                "message": str(e),
            }

    def _calculate_technical_indicators(self, data: pd.DataFrame) -> List[Dict]:
        """è®¡ç®—æŠ€æœ¯æŒ‡æ ‡"""
        try:
            import numpy as np
            close_prices = data["close"].values

            # è®¡ç®—RSI
            rsi = self._calculate_rsi(close_prices)

            # è®¡ç®—MACD
            macd_value = self._calculate_macd(close_prices)

            # è®¡ç®—KDJ
            kdj_value = self._calculate_kdj(data)

            # è®¡ç®—BOLL
            boll_value = self._calculate_boll(close_prices)

            indicators = [
                {
                    "name": "RSI",
                    "value": round(rsi, 2),
                    "signal": self._get_rsi_signal(rsi),
                    "color": self._get_rsi_color(rsi),
                    "icon": "mdi-chart-line",
                    "description": "ç›¸å¯¹å¼ºå¼±æŒ‡æ•°",
                },
                {
                    "name": "MACD",
                    "value": round(macd_value, 2),
                    "signal": self._get_macd_signal(macd_value),
                    "color": self._get_macd_color(macd_value),
                    "icon": "mdi-chart-areaspline",
                    "description": "ç§»åŠ¨å¹³å‡æ”¶æ•›æ•£åº¦",
                },
                {
                    "name": "KDJ",
                    "value": round(kdj_value, 2),
                    "signal": self._get_kdj_signal(kdj_value),
                    "color": self._get_kdj_color(kdj_value),
                    "icon": "mdi-chart-scatter-plot",
                    "description": "éšæœºæŒ‡æ ‡",
                },
                {
                    "name": "BOLL",
                    "value": round(boll_value, 2),
                    "signal": self._get_boll_signal(boll_value),
                    "color": self._get_boll_color(boll_value),
                    "icon": "mdi-chart-box",
                    "description": "å¸ƒæ—å¸¦æŒ‡æ ‡",
                },
            ]

            return indicators

        except Exception as e:
            logger.error(f"è®¡ç®—æŠ€æœ¯æŒ‡æ ‡å¤±è´¥: {e}")
            return self._get_estimated_indicators()

    def _get_estimated_indicators(self) -> List[Dict]:
        """è·å–ä¼°ç®—çš„æŠ€æœ¯æŒ‡æ ‡"""
        import random

        # ç”Ÿæˆåˆç†èŒƒå›´å†…çš„éšæœºå€¼
        rsi = random.uniform(45, 65)
        macd = random.uniform(-0.5, 0.5)
        kdj = random.uniform(40, 70)
        boll = random.uniform(-1, 1)

        return [
            {
                "name": "RSI",
                "value": round(rsi, 2),
                "signal": self._get_rsi_signal(rsi),
                "color": self._get_rsi_color(rsi),
                "icon": "mdi-chart-line",
                "description": "ç›¸å¯¹å¼ºå¼±æŒ‡æ•°(ä¼°ç®—)",
            },
            {
                "name": "MACD",
                "value": round(macd, 2),
                "signal": self._get_macd_signal(macd),
                "color": self._get_macd_color(macd),
                "icon": "mdi-chart-areaspline",
                "description": "ç§»åŠ¨å¹³å‡æ”¶æ•›æ•£åº¦(ä¼°ç®—)",
            },
            {
                "name": "KDJ",
                "value": round(kdj, 2),
                "signal": self._get_kdj_signal(kdj),
                "color": self._get_kdj_color(kdj),
                "icon": "mdi-chart-scatter-plot",
                "description": "éšæœºæŒ‡æ ‡(ä¼°ç®—)",
            },
            {
                "name": "BOLL",
                "value": round(boll, 2),
                "signal": self._get_boll_signal(boll),
                "color": self._get_boll_color(boll),
                "icon": "mdi-chart-box",
                "description": "å¸ƒæ—å¸¦æŒ‡æ ‡(ä¼°ç®—)",
            },
        ]

    def _calculate_rsi(self, prices, period: int = 14) -> float:
        """è®¡ç®—RSI"""
        try:
            import numpy as np
            if len(prices) < period + 1:
                return 50.0

            deltas = np.diff(prices)
            gains = np.where(deltas > 0, deltas, 0)
            losses = np.where(deltas < 0, -deltas, 0)

            avg_gain = np.mean(gains[-period:])
            avg_loss = np.mean(losses[-period:])

            if avg_loss == 0:
                return 100.0

            rs = avg_gain / avg_loss
            rsi = 100 - (100 / (1 + rs))

            return float(rsi)
        except:
            return 50.0

    def _calculate_macd(self, prices) -> float:
        """è®¡ç®—MACD"""
        try:
            if len(prices) < 26:
                return 0.0

            import pandas as pd

            ema12 = pd.Series(prices).ewm(span=12, adjust=False).mean().iloc[-1]
            ema26 = pd.Series(prices).ewm(span=26, adjust=False).mean().iloc[-1]

            macd = ema12 - ema26
            return float(macd)
        except:
            return 0.0

    def _calculate_kdj(self, data: pd.DataFrame, period: int = 9) -> float:
        """è®¡ç®—KDJ"""
        try:
            if len(data) < period:
                return 50.0

            recent_data = data.tail(period)

            low_min = recent_data["low"].min()
            high_max = recent_data["high"].max()

            if high_max == low_min:
                return 50.0

            rsv = (recent_data["close"].iloc[-1] - low_min) / (high_max - low_min) * 100

            return float(rsv)
        except:
            return 50.0

    def _calculate_boll(self, prices, period: int = 20) -> float:
        """è®¡ç®—å¸ƒæ—å¸¦"""
        try:
            import numpy as np
            if len(prices) < period:
                return 1.0

            recent_prices = prices[-period:]
            mean = np.mean(recent_prices)
            std = np.std(recent_prices)

            current_price = prices[-1]

            if std == 0:
                return 1.0

            return float((current_price - mean) / std)
        except:
            return 1.0

    # ä¿¡å·åˆ¤æ–­æ–¹æ³•
    def _get_rsi_signal(self, rsi: float) -> str:
        if rsi >= 70:
            return "è¶…ä¹°"
        elif rsi >= 50:
            return "ä¸­æ€§åå¼º"
        elif rsi >= 30:
            return "ä¸­æ€§"
        else:
            return "è¶…å–"

    def _get_rsi_color(self, rsi: float) -> str:
        if rsi >= 70 or rsi <= 30:
            return "warning"
        elif rsi >= 50:
            return "success"
        else:
            return "info"

    def _get_macd_signal(self, macd: float) -> str:
        if macd > 0.5:
            return "å¼ºä¹°å…¥"
        elif macd > 0:
            return "ä¹°å…¥"
        elif macd > -0.5:
            return "å–å‡º"
        else:
            return "å¼ºå–å‡º"

    def _get_macd_color(self, macd: float) -> str:
        return "success" if macd > 0 else "error"

    def _get_kdj_signal(self, kdj: float) -> str:
        if kdj >= 80:
            return "è¶…ä¹°"
        elif kdj >= 50:
            return "ä¸­æ€§åå¼º"
        elif kdj >= 20:
            return "ä¸­æ€§"
        else:
            return "è¶…å–"

    def _get_kdj_color(self, kdj: float) -> str:
        if kdj >= 80:
            return "warning"
        elif kdj >= 50:
            return "success"
        elif kdj >= 20:
            return "primary"
        else:
            return "error"

    def _get_boll_signal(self, boll: float) -> str:
        if boll > 2:
            return "çªç ´ä¸Šè½¨"
        elif boll > 1:
            return "æ¥è¿‘ä¸Šè½¨"
        elif boll > -1:
            return "ä¸­è½¨åŒºé—´"
        elif boll > -2:
            return "æ¥è¿‘ä¸‹è½¨"
        else:
            return "çªç ´ä¸‹è½¨"

    def _get_boll_color(self, boll: float) -> str:
        if abs(boll) > 2:
            return "warning"
        elif abs(boll) > 1:
            return "info"
        else:
            return "success"

    async def fetch_market_news_data(self, limit: int = 10, include_tonghuashun: bool = True) -> Dict:
        """
        è·å–å¸‚åœºèµ„è®¯æ•°æ®ï¼ˆæ•´åˆå¤šæ•°æ®æºï¼‰
        
        Args:
            limit: è·å–æ•°é‡é™åˆ¶
            include_tonghuashun: æ˜¯å¦åŒ…å«åŒèŠ±é¡ºæ•°æ®æºï¼ˆç ”æŠ¥ã€å¿«è®¯ï¼‰
        
        Returns:
            æ–°é—»æ•°æ®å­—å…¸
        """
        try:
            logger.info(f"ğŸ“° è·å–å¸‚åœºèµ„è®¯æ•°æ® (limit={limit}, åŒèŠ±é¡º={include_tonghuashun})...")

            if not self.initialized:
                self.initialize()

            all_news = []
            
            # 1. ä»æ•°æ®åº“è·å–ä¼ ç»Ÿæ–°é—»ï¼ˆAKShare/ä¸œè´¢ï¼‰
            try:
                news_df = self.db_manager.get_news_data(limit=limit)

                if news_df.empty:
                    logger.warning("âš ï¸ æ•°æ®åº“æ— æ–°é—»ï¼Œå°è¯•ä»ç½‘ç»œè·å–...")
                    news_df = self.alternative_collector.fetch_news_data(limit=limit)

                    if not news_df.empty:
                        self.db_manager.save_news_data(news_df)

                if not news_df.empty:
                    # å¤„ç†ä¼ ç»Ÿæ–°é—»
                    traditional_news = self._process_news_data(news_df, limit)
                    all_news.extend(traditional_news)
                    logger.info(f"âœ… è·å–ä¼ ç»Ÿæ–°é—» {len(traditional_news)} æ¡")

            except Exception as e:
                logger.warning(f"è·å–ä¼ ç»Ÿæ–°é—»å¤±è´¥: {e}")
            
            # 2. ä»åŒèŠ±é¡ºè·å–ç ”æŠ¥å’Œå¿«è®¯ï¼ˆå¯é€‰ï¼‰
            if include_tonghuashun and self.tonghuashun_collector:
                try:
                    # å¹¶è¡Œè·å–ç ”æŠ¥å’Œå¿«è®¯
                    tasks = [
                        self.tonghuashun_collector.fetch_research_reports(limit=max(5, limit // 2)),
                        self.tonghuashun_collector.fetch_flash_news(limit=max(10, limit // 2)),
                    ]
                    
                    results = await asyncio.gather(*tasks, return_exceptions=True)
                    
                    # å¤„ç†ç ”æŠ¥
                    if isinstance(results[0], pd.DataFrame) and not results[0].empty:
                        reports = self._process_tonghuashun_data(results[0], data_type='research')
                        all_news.extend(reports)
                        logger.info(f"âœ… è·å–åŒèŠ±é¡ºç ”æŠ¥ {len(reports)} æ¡")
                    
                    # å¤„ç†å¿«è®¯
                    if isinstance(results[1], pd.DataFrame) and not results[1].empty:
                        flash = self._process_tonghuashun_data(results[1], data_type='flash')
                        all_news.extend(flash)
                        logger.info(f"âœ… è·å–åŒèŠ±é¡ºå¿«è®¯ {len(flash)} æ¡")
                
                except Exception as e:
                    logger.warning(f"è·å–åŒèŠ±é¡ºæ•°æ®å¤±è´¥: {e}")
            
            # 3. æŒ‰æ—¶é—´æ’åºå¹¶é™åˆ¶æ•°é‡
            if all_news:
                all_news.sort(key=lambda x: x.get('time', ''), reverse=True)
                all_news = all_news[:limit]

            if not all_news:
                logger.warning("âš ï¸ æ— æ–°é—»æ•°æ®")
                return {"success": False, "data": [], "message": "æ— æ–°é—»æ•°æ®"}

            logger.info(f"âœ… å¸‚åœºèµ„è®¯æ•°æ®è·å–æˆåŠŸ: {len(all_news)} æ¡ï¼ˆå«å¤šæ•°æ®æºï¼‰")
            return {"success": True, "data": all_news, "count": len(all_news)}

        except Exception as e:
            logger.error(f"âŒ è·å–å¸‚åœºèµ„è®¯æ•°æ®å¤±è´¥: {e}")
            import traceback

            traceback.print_exc()
            return {"success": False, "data": [], "message": str(e)}

    def _process_news_data(self, news_df: pd.DataFrame, limit: int) -> List[Dict]:
        """å¤„ç†æ–°é—»æ•°æ®"""
        news_list = []

        for idx, row in news_df.head(limit).iterrows():
            try:
                title = str(row.get("title", row.get("æ ‡é¢˜", "æ— æ ‡é¢˜")))
                content = str(row.get("content", row.get("å†…å®¹", "")))

                # ç”Ÿæˆæ‘˜è¦
                summary = content[:100] + "..." if len(content) > 100 else content

                # è·å–æ—¶é—´
                time_str = row.get("time", row.get("date", row.get("æ—¥æœŸ", None)))
                if time_str:
                    try:
                        if isinstance(time_str, str):
                            news_time = datetime.fromisoformat(
                                time_str.replace("T", " ").split(".")[0]
                            )
                        else:
                            news_time = time_str
                    except:
                        news_time = datetime.now()
                else:
                    news_time = datetime.now()

                # åˆ¤æ–­æ˜¯å¦ä¸ºé‡è¦æ–°é—»
                important_keywords = [
                    "å¤®è¡Œ",
                    "é™å‡†",
                    "åŠ æ¯",
                    "é‡å¤§",
                    "ç´§æ€¥",
                    "æš´è·Œ",
                    "æš´æ¶¨",
                    "æ”¿ç­–",
                    "ç›‘ç®¡",
                ]
                is_important = any(
                    keyword in title or keyword in content
                    for keyword in important_keywords
                )

                news_list.append(
                    {
                        "id": idx + 1,
                        "title": title,
                        "summary": summary,
                        "time": news_time.isoformat(),
                        "type": "important" if is_important else "normal",
                    }
                )

            except Exception as e:
                logger.warning(f"å¤„ç†æ–°é—»æ•°æ®å¤±è´¥: {e}")
                continue

        return news_list
    
    def _process_tonghuashun_data(self, df: pd.DataFrame, data_type: str = 'research') -> List[Dict]:
        """
        å¤„ç†åŒèŠ±é¡ºæ•°æ®ï¼ˆç ”æŠ¥ã€å¿«è®¯ï¼‰
        
        Args:
            df: åŒèŠ±é¡ºæ•°æ®DataFrame
            data_type: æ•°æ®ç±»å‹ï¼Œ'research'ï¼ˆç ”æŠ¥ï¼‰æˆ–'flash'ï¼ˆå¿«è®¯ï¼‰
        
        Returns:
            å¤„ç†åçš„æ•°æ®åˆ—è¡¨
        """
        result_list = []
        
        for idx, row in df.iterrows():
            try:
                title = str(row.get('title', ''))
                summary = str(row.get('summary', row.get('content', '')))
                
                # è·å–æ—¶é—´
                time_str = row.get('date', row.get('time', ''))
                if time_str:
                    try:
                        if isinstance(time_str, str):
                            news_time = datetime.fromisoformat(time_str.replace("T", " ").split(".")[0])
                        else:
                            news_time = time_str
                    except:
                        news_time = datetime.now()
                else:
                    news_time = datetime.now()
                
                # æ ¹æ®æ•°æ®ç±»å‹è®¾ç½®typeå­—æ®µ
                if data_type == 'research':
                    news_type = 'research_report'  # ç ”æŠ¥
                elif data_type == 'flash':
                    news_type = 'flash'  # å¿«è®¯
                else:
                    news_type = 'normal'
                
                result_list.append({
                    'id': f"ths_{idx}_{int(news_time.timestamp())}",
                    'title': title,
                    'summary': summary[:200] + '...' if len(summary) > 200 else summary,
                    'time': news_time.isoformat(),
                    'type': news_type,
                    'source': row.get('source', 'åŒèŠ±é¡º'),
                    'institution': row.get('institution', ''),  # ç ”æŠ¥æœºæ„
                    'link': row.get('link', ''),  # åŸæ–‡é“¾æ¥
                })
                
            except Exception as e:
                logger.debug(f"å¤„ç†åŒèŠ±é¡ºæ•°æ®å¤±è´¥: {e}")
                continue
        
        return result_list

    async def update_all_data(self) -> Dict:
        """æ›´æ–°æ‰€æœ‰æ•°æ®"""
        try:
            logger.info("ğŸ”„ å¼€å§‹æ›´æ–°æ‰€æœ‰æ™ºèƒ½åˆ†æé¡µé¢æ•°æ®...")

            results = {
                "sector_analysis": False,
                "market_sentiment": False,
                "technical_indicators": False,
                "market_news": False,
                "errors": [],
            }

            # 1. æ›´æ–°æ¿å—æ•°æ®
            try:
                sector_result = await self.fetch_sector_analysis_data()
                results["sector_analysis"] = sector_result.get("success", False)
            except Exception as e:
                results["errors"].append(f"æ¿å—åˆ†æ: {str(e)}")

            # 2. æ›´æ–°å¸‚åœºæƒ…ç»ª
            try:
                sentiment_result = await self.fetch_market_sentiment_data()
                results["market_sentiment"] = sentiment_result.get("success", False)
            except Exception as e:
                results["errors"].append(f"å¸‚åœºæƒ…ç»ª: {str(e)}")

            # 3. æ›´æ–°æŠ€æœ¯æŒ‡æ ‡
            try:
                indicators_result = await self.fetch_technical_indicators_data()
                results["technical_indicators"] = indicators_result.get("success", False)
            except Exception as e:
                results["errors"].append(f"æŠ€æœ¯æŒ‡æ ‡: {str(e)}")

            # 4. æ›´æ–°å¸‚åœºèµ„è®¯
            try:
                news_result = await self.fetch_market_news_data(limit=10)
                results["market_news"] = news_result.get("success", False)
            except Exception as e:
                results["errors"].append(f"å¸‚åœºèµ„è®¯: {str(e)}")

            success_count = sum([v for k, v in results.items() if k != "errors"])
            logger.info(f"âœ… æ•°æ®æ›´æ–°å®Œæˆ: {success_count}/4 æˆåŠŸ")

            return results

        except Exception as e:
            logger.error(f"âŒ æ›´æ–°æ‰€æœ‰æ•°æ®å¤±è´¥: {e}")
            return {"error": str(e)}


# å…¨å±€å®ä¾‹
_coordinator = None


def get_data_pipeline_coordinator() -> DataPipelineCoordinator:
    """è·å–æ•°æ®ç®¡é“åè°ƒå™¨å•ä¾‹"""
    global _coordinator
    if _coordinator is None:
        _coordinator = DataPipelineCoordinator()
        _coordinator.initialize()
    return _coordinator


# ä¾¿æ·å‡½æ•°
async def fetch_all_market_intelligence_data():
    """è·å–æ‰€æœ‰å¸‚åœºæƒ…æŠ¥æ•°æ®"""
    coordinator = get_data_pipeline_coordinator()
    return await coordinator.update_all_data()

