"""
VaR (Value at Risk) è®¡ç®—å™¨
è®¡ç®—æŠ•èµ„ç»„åˆçš„é£é™©ä»·å€¼
"""

from __future__ import annotations

from enum import Enum
from typing import Dict, List, Optional, Union

import numpy as np
import pandas as pd
from scipy import stats

from common.logging_system import setup_logger

LOGGER = setup_logger("var_calculator")


class VaRMethod(Enum):
    """VaRè®¡ç®—æ–¹æ³•"""

    HISTORICAL = "historical"  # å†å²æ¨¡æ‹Ÿæ³•
    PARAMETRIC = "parametric"  # å‚æ•°æ³•(æ–¹å·®-åæ–¹å·®)
    MONTE_CARLO = "monte_carlo"  # è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿ


class VaRCalculator:
    """VaRè®¡ç®—å™¨

    è®¡ç®—ä¸åŒç½®ä¿¡æ°´å¹³ä¸‹çš„é£é™©ä»·å€¼(VaR)å’Œæ¡ä»¶é£é™©ä»·å€¼(CVaR)
    """

    def __init__(self):
        """åˆå§‹åŒ–VaRè®¡ç®—å™¨"""
        LOGGER.info("ğŸ“Š VaRè®¡ç®—å™¨åˆå§‹åŒ–å®Œæˆ")

    def calculate_var(
        self,
        returns: Union[pd.Series, np.ndarray, List[float]],
        confidence_level: float = 0.95,
        method: VaRMethod = VaRMethod.HISTORICAL,
        portfolio_value: float = 1.0,
        time_horizon: int = 1,
    ) -> Dict[str, float]:
        """è®¡ç®—VaR

        Args:
            returns: æ”¶ç›Šç‡åºåˆ—
            confidence_level: ç½®ä¿¡æ°´å¹³ (0.90, 0.95, 0.99)
            method: è®¡ç®—æ–¹æ³•
            portfolio_value: æŠ•èµ„ç»„åˆä»·å€¼
            time_horizon: æ—¶é—´è·¨åº¦ï¼ˆå¤©ï¼‰

        Returns:
            åŒ…å«VaRå’ŒCVaRçš„å­—å…¸
        """
        try:
            # è½¬æ¢ä¸ºnumpyæ•°ç»„
            if isinstance(returns, (pd.Series, list)):
                returns = np.array(returns)

            # è¿‡æ»¤æ— æ•ˆå€¼
            returns = returns[~np.isnan(returns)]

            if len(returns) < 30:
                LOGGER.warning("âš ï¸ æ•°æ®ç‚¹è¿‡å°‘ï¼ŒVaRè®¡ç®—å¯èƒ½ä¸å‡†ç¡®")

            # æ ¹æ®æ–¹æ³•è®¡ç®—VaR
            if method == VaRMethod.HISTORICAL:
                var = self._historical_var(returns, confidence_level)
            elif method == VaRMethod.PARAMETRIC:
                var = self._parametric_var(returns, confidence_level)
            elif method == VaRMethod.MONTE_CARLO:
                var = self._monte_carlo_var(returns, confidence_level)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ–¹æ³•: {method}")

            # è®¡ç®—CVaR (æ¡ä»¶VaR)
            cvar = self._calculate_cvar(returns, var)

            # è°ƒæ•´æ—¶é—´è·¨åº¦
            var_adjusted = var * np.sqrt(time_horizon)
            cvar_adjusted = cvar * np.sqrt(time_horizon)

            # è½¬æ¢ä¸ºé‡‘é¢
            var_amount = portfolio_value * abs(var_adjusted)
            cvar_amount = portfolio_value * abs(cvar_adjusted)

            result = {
                "var": var,  # VaR (æ¯”ä¾‹)
                "cvar": cvar,  # CVaR (æ¯”ä¾‹)
                "var_adjusted": var_adjusted,  # è°ƒæ•´æ—¶é—´è·¨åº¦åçš„VaR
                "cvar_adjusted": cvar_adjusted,  # è°ƒæ•´æ—¶é—´è·¨åº¦åçš„CVaR
                "var_amount": var_amount,  # VaRé‡‘é¢
                "cvar_amount": cvar_amount,  # CVaRé‡‘é¢
                "confidence_level": confidence_level,
                "time_horizon": time_horizon,
                "method": method.value,
                "portfolio_value": portfolio_value,
            }

            LOGGER.info(
                f"âœ… VaRè®¡ç®—å®Œæˆ: "
                f"VaR={var:.4f} ({var_amount:,.2f}), "
                f"CVaR={cvar:.4f} ({cvar_amount:,.2f})"
            )

            return result

        except Exception as e:
            LOGGER.error(f"âŒ VaRè®¡ç®—å¤±è´¥: {e}", exc_info=True)
            return {"var": 0.0, "cvar": 0.0, "error": str(e)}

    def _historical_var(self, returns: np.ndarray, confidence_level: float) -> float:
        """å†å²æ¨¡æ‹Ÿæ³•è®¡ç®—VaR

        æœ€ç®€å•ç›´è§‚çš„æ–¹æ³•ï¼Œç›´æ¥ä½¿ç”¨å†å²æ”¶ç›Šç‡çš„åˆ†ä½æ•°
        """
        percentile = (1 - confidence_level) * 100
        var = np.percentile(returns, percentile)
        return float(var)

    def _parametric_var(self, returns: np.ndarray, confidence_level: float) -> float:
        """å‚æ•°æ³•è®¡ç®—VaR

        å‡è®¾æ”¶ç›Šç‡æœä»æ­£æ€åˆ†å¸ƒ
        """
        mean = np.mean(returns)
        std = np.std(returns)

        # è·å–ç½®ä¿¡æ°´å¹³å¯¹åº”çš„zå€¼
        z_score = stats.norm.ppf(1 - confidence_level)

        # VaR = Î¼ + z*Ïƒ
        var = mean + z_score * std
        return float(var)

    def _monte_carlo_var(
        self, returns: np.ndarray, confidence_level: float, n_simulations: int = 10000
    ) -> float:
        """è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿæ³•è®¡ç®—VaR

        é€šè¿‡å¤§é‡æ¨¡æ‹Ÿç”Ÿæˆæ”¶ç›Šç‡åˆ†å¸ƒ
        """
        mean = np.mean(returns)
        std = np.std(returns)

        # ç”Ÿæˆæ¨¡æ‹Ÿæ”¶ç›Šç‡
        simulated_returns = np.random.normal(mean, std, n_simulations)

        # è®¡ç®—VaR
        percentile = (1 - confidence_level) * 100
        var = np.percentile(simulated_returns, percentile)
        return float(var)

    def _calculate_cvar(self, returns: np.ndarray, var: float) -> float:
        """è®¡ç®—CVaR (æ¡ä»¶VaR / æœŸæœ›æŸå¤±)

        CVaRæ˜¯æŸå¤±è¶…è¿‡VaRçš„æ¡ä»¶æœŸæœ›
        """
        # æ‰¾å‡ºæ‰€æœ‰æŸå¤±è¶…è¿‡VaRçš„æƒ…å†µ
        tail_losses = returns[returns <= var]

        if len(tail_losses) > 0:
            cvar = np.mean(tail_losses)
        else:
            cvar = var

        return float(cvar)

    def calculate_marginal_var(
        self,
        portfolio_returns: pd.DataFrame,
        weights: np.ndarray,
        confidence_level: float = 0.95,
    ) -> Dict[str, float]:
        """è®¡ç®—è¾¹é™…VaR

        è¡¡é‡æ¯ä¸ªèµ„äº§å¯¹ç»„åˆVaRçš„è´¡çŒ®

        Args:
            portfolio_returns: å„èµ„äº§æ”¶ç›Šç‡ (DataFrame)
            weights: èµ„äº§æƒé‡
            confidence_level: ç½®ä¿¡æ°´å¹³

        Returns:
            å„èµ„äº§çš„è¾¹é™…VaR
        """
        try:
            # è®¡ç®—ç»„åˆæ”¶ç›Šç‡
            portfolio_return = np.dot(portfolio_returns, weights)

            # è®¡ç®—ç»„åˆVaR
            portfolio_var = self.calculate_var(
                portfolio_return, confidence_level, VaRMethod.HISTORICAL
            )["var"]

            # è®¡ç®—æ¯ä¸ªèµ„äº§çš„è¾¹é™…VaR
            marginal_vars = {}

            for i, column in enumerate(portfolio_returns.columns):
                # å¾®å°æ‰°åŠ¨
                delta = 0.01
                new_weights = weights.copy()
                new_weights[i] += delta
                new_weights = new_weights / np.sum(new_weights)  # é‡æ–°å½’ä¸€åŒ–

                # è®¡ç®—æ–°çš„VaR
                new_return = np.dot(portfolio_returns, new_weights)
                new_var = self.calculate_var(
                    new_return, confidence_level, VaRMethod.HISTORICAL
                )["var"]

                # è¾¹é™…VaR
                marginal_var = (new_var - portfolio_var) / delta
                marginal_vars[column] = float(marginal_var)

            LOGGER.info(f"âœ… è¾¹é™…VaRè®¡ç®—å®Œæˆ: {len(marginal_vars)}ä¸ªèµ„äº§")

            return marginal_vars

        except Exception as e:
            LOGGER.error(f"âŒ è¾¹é™…VaRè®¡ç®—å¤±è´¥: {e}", exc_info=True)
            return {}

    def calculate_component_var(
        self,
        portfolio_returns: pd.DataFrame,
        weights: np.ndarray,
        confidence_level: float = 0.95,
    ) -> Dict[str, float]:
        """è®¡ç®—æˆåˆ†VaR

        å°†ç»„åˆVaRåˆ†è§£ä¸ºå„èµ„äº§çš„è´¡çŒ®

        Args:
            portfolio_returns: å„èµ„äº§æ”¶ç›Šç‡ (DataFrame)
            weights: èµ„äº§æƒé‡
            confidence_level: ç½®ä¿¡æ°´å¹³

        Returns:
            å„èµ„äº§çš„æˆåˆ†VaR
        """
        try:
            # è®¡ç®—åæ–¹å·®çŸ©é˜µ
            cov_matrix = portfolio_returns.cov()

            # è®¡ç®—ç»„åˆæ ‡å‡†å·®
            portfolio_variance = np.dot(weights.T, np.dot(cov_matrix, weights))
            portfolio_std = np.sqrt(portfolio_variance)

            # è·å–zå€¼
            z_score = abs(stats.norm.ppf(1 - confidence_level))

            # ç»„åˆVaR
            portfolio_var = z_score * portfolio_std

            # è®¡ç®—æ¯ä¸ªèµ„äº§çš„æˆåˆ†VaR
            component_vars = {}

            for i, column in enumerate(portfolio_returns.columns):
                # èµ„äº§iå¯¹ç»„åˆæ–¹å·®çš„è´¡çŒ®
                marginal_contribution = (
                    np.dot(cov_matrix.iloc[i], weights) / portfolio_std
                )

                # æˆåˆ†VaR = æƒé‡ * è¾¹é™…è´¡çŒ® * VaR
                component_var = weights[i] * marginal_contribution * portfolio_var
                component_vars[column] = float(component_var)

            LOGGER.info(f"âœ… æˆåˆ†VaRè®¡ç®—å®Œæˆ: {len(component_vars)}ä¸ªèµ„äº§")

            return component_vars

        except Exception as e:
            LOGGER.error(f"âŒ æˆåˆ†VaRè®¡ç®—å¤±è´¥: {e}", exc_info=True)
            return {}

    def backtest_var(
        self,
        returns: pd.Series,
        confidence_level: float = 0.95,
        window_size: int = 252,
        method: VaRMethod = VaRMethod.HISTORICAL,
    ) -> Dict:
        """å›æµ‹VaRæ¨¡å‹

        æ£€éªŒVaRæ¨¡å‹çš„å‡†ç¡®æ€§

        Args:
            returns: æ”¶ç›Šç‡åºåˆ—
            confidence_level: ç½®ä¿¡æ°´å¹³
            window_size: æ»šåŠ¨çª—å£å¤§å°
            method: è®¡ç®—æ–¹æ³•

        Returns:
            å›æµ‹ç»“æœ
        """
        try:
            violations = 0
            total_obs = 0
            var_series = []

            for i in range(window_size, len(returns)):
                # ä½¿ç”¨å†å²æ•°æ®è®¡ç®—VaR
                historical_returns = returns[i - window_size : i].values

                var_result = self.calculate_var(
                    historical_returns, confidence_level, method
                )
                var = var_result["var"]
                var_series.append(var)

                # æ£€æŸ¥æ˜¯å¦è¿åVaR
                actual_return = returns.iloc[i]
                if actual_return < var:
                    violations += 1

                total_obs += 1

            # è®¡ç®—è¿åç‡
            violation_rate = violations / total_obs if total_obs > 0 else 0
            expected_violation_rate = 1 - confidence_level

            # Kupiecæ£€éªŒ (ä¼¼ç„¶æ¯”æ£€éªŒ)
            if violations > 0 and violations < total_obs:
                lr_stat = -2 * (
                    np.log(
                        (expected_violation_rate**violations)
                        * ((1 - expected_violation_rate) ** (total_obs - violations))
                    )
                    - np.log(
                        (violation_rate**violations)
                        * ((1 - violation_rate) ** (total_obs - violations))
                    )
                )
                p_value = 1 - stats.chi2.cdf(lr_stat, df=1)
            else:
                lr_stat = 0
                p_value = 1

            result = {
                "violations": violations,
                "total_observations": total_obs,
                "violation_rate": violation_rate,
                "expected_violation_rate": expected_violation_rate,
                "kupiec_lr_stat": lr_stat,
                "kupiec_p_value": p_value,
                "model_adequate": p_value > 0.05,  # 5%æ˜¾è‘—æ€§æ°´å¹³
                "var_series": var_series,
            }

            LOGGER.info(
                f"âœ… VaRå›æµ‹å®Œæˆ: "
                f"è¿åç‡={violation_rate:.2%} (é¢„æœŸ={expected_violation_rate:.2%}), "
                f"æ¨¡å‹{'å……åˆ†' if result['model_adequate'] else 'ä¸å……åˆ†'}"
            )

            return result

        except Exception as e:
            LOGGER.error(f"âŒ VaRå›æµ‹å¤±è´¥: {e}", exc_info=True)
            return {"error": str(e)}


# å…¨å±€å•ä¾‹
_calculator_instance = None


def get_var_calculator() -> VaRCalculator:
    """è·å–VaRè®¡ç®—å™¨å•ä¾‹"""
    global _calculator_instance
    if _calculator_instance is None:
        _calculator_instance = VaRCalculator()
    return _calculator_instance
